{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_exclude = [\"predictions\", \"labels\", \"generations\", \"unfiltered_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diptanu-fBERT_SEQ_CLS_VANILLA_FT_davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism_NO-ES_RESULTS.json\n",
      "diptanu-fBERT_SEQ_CLS_VANILLA_FT_hateval-immigrant-TO-waseem-racism-TO-ibereval_NO-ES_RESULTS.json\n",
      "FacebookAI-roberta-base_SEQ_CLS_AGEM_davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism_mem_size_proportion=0.01NO-ES_RESULTS.json\n",
      "FacebookAI-roberta-base_SEQ_CLS_VANILLA_FT_davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism_NO-ES_RESULTS.json\n",
      "FacebookAI-roberta-base_SEQ_CLS_VANILLA_FT_evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant_NO-ES_RESULTS.json\n",
      "FacebookAI-roberta-base_SEQ_CLS_VANILLA_FT_hateval-immigrant-TO-waseem-racism-TO-ibereval_NO-ES_RESULTS.json\n",
      "fBERTdavidson_ewc_lambda=2000NO-ES_RESULTS.json\n",
      "fBERT_AGEM_evalita-proportion0025_RESULTS.json\n",
      "fBERT_AGEM_evalita_mem_size_proportion001_RESULTS.json\n",
      "fBERT_AGEM_evalita_mem_size_proportion005_RESULTS.json\n",
      "fBERT_AGEM_hatevalmem_size_proportion0025_RESULTS.json\n",
      "fBERT_AGEM_hateval_mem_size_proportion001_RESULTS.json\n",
      "fBERT_AGEM_hateval_mem_size_proportion005_RESULTS.json\n",
      "fBERT_EWC_davidson_ewc_lambda1000NO-ES_RESULTS.json\n",
      "fBERT_EWC_davidson_ewc_lambda1500_RESULTS.json\n",
      "fBERT_VANILLA_FT_evalita_NO-ES_RESULTS.json\n",
      "GroNLP-hateBERT_SEQ_CLS_VANILLA_FT_davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism_NO-ES_RESULTS.json\n",
      "hateBERT_MAS_davidson_mas_lambda1000_NO-ES_RESULTS.json\n",
      "hateBERT_MAS_davidson_mas_lambda1500_NO-ES_RESULTS.json\n",
      "hateBERT_MAS_davidson_mas_lambda500NO-ES_RESULTS.json\n",
      "roberta-base_AGEM_davidson_mem_size_0025NO-ES_RESULTS.json\n",
      "roberta-base_AGEM_evalita_mem_size_proportion001NO-ES_RESULTS.json\n",
      "roberta-base_AGEM_evalita_mem_size_proportion0025NO-ES_RESULTS.json\n",
      "roberta-base_AGEM_evalita_mem_size_proportion005NO-ES_RESULTS.json\n",
      "roberta-base_AGEM_hateval_mem_size_proportion001NO-ES_RESULTS.json\n",
      "roberta-base_AGEM_hateval_mem_size_proportion0025NO-ES_RESULTS.json\n",
      "roberta-base_AGEM_hateval_mem_size_proportion005NO-ES_RESULTS.json\n"
     ]
    }
   ],
   "source": [
    "list_files = [file_ for file_ in os.listdir(\"Dump/\") if file_.endswith(\"RESULTS.json\")]\n",
    "json_files = []\n",
    "csvs = []\n",
    "for json_file in list_files:\n",
    "    print(json_file)\n",
    "    with open(\"Dump/\" + json_file, \"r\") as f:\n",
    "        js = json.load(f)\n",
    "        json_files.append(js)\n",
    "\n",
    "        for d in js:\n",
    "            for key in keys_to_exclude:\n",
    "                d.pop(key, None)\n",
    "        df = pd.DataFrame(js, columns=js[0].keys())\n",
    "        csvs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shots = pd.read_csv(r\"Dump/Zero_Shots/df_plm_zero_shots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from continual_hate.metrics import transform_df_to_cl_metrics\n",
    "from continual_hate.constants import dict_name_experiments_domain_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
       "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
       "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
       "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
       "       'current_num_samples_training', 'cumulative_samples_trained',\n",
       "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
       "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
       "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.91661695 0.77270589 0.61316242 0.45790817 0.34820422 0.59587484]\n",
      " [0.91297956 0.78015968 0.6265587  0.46257979 0.47471831 0.62687747]\n",
      " [0.90108164 0.72015788 0.75612445 0.41876551 0.50066344 0.59884611]\n",
      " [0.84952315 0.74882483 0.79133614 0.47332395 0.36490721 0.65547502]\n",
      " [0.75601473 0.62646567 0.8132716  0.54793757 0.61361693 0.46220312]\n",
      " [0.77645855 0.6451739  0.82198104 0.61307277 0.62057244 0.66170927]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.875      0.57667934 0.51565378 0.1852349  0.60458313 0.29799427]\n",
      " [0.86861314 0.5883959  0.51750973 0.19440746 0.62959077 0.35072464]\n",
      " [0.8490566  0.47049313 0.69801085 0.10662824 0.63974495 0.28472222]\n",
      " [0.78787879 0.53923117 0.7706422  0.61667541 0.60522425 0.44551591]\n",
      " [0.60194175 0.2851365  0.75       0.38629283 0.67792662 0.00502513]\n",
      " [0.63869464 0.32239382 0.7628866  0.5488     0.67960024 0.39005736]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.48816501 0.68615569 0.63757079]\n",
      " [0.51853331 0.82029105 0.38280195]\n",
      " [0.53361311 0.81321654 0.79197749]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61381896 0.4789357  0.50328228]\n",
      " [0.48898365 0.68965517 0.00704225]\n",
      " [0.59241706 0.68742791 0.75043029]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.9217285  0.73948689 0.72243176 0.49016739 0.54105049 0.52891525]\n",
      " [0.92229495 0.77149071 0.76195284 0.62487487 0.55236473 0.63144347]\n",
      " [0.92675577 0.75230328 0.77513683 0.5379291  0.5618167  0.52648475]\n",
      " [0.89484862 0.75709716 0.78958389 0.65213524 0.4472428  0.63171036]\n",
      " [0.87823044 0.69210149 0.79440708 0.62641346 0.65687646 0.50778167]\n",
      " [0.90159187 0.73737798 0.82234469 0.558748   0.61430756 0.65589304]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88203267 0.50786164 0.62761506 0.24052288 0.64487535 0.15151515]\n",
      " [0.88330341 0.57162726 0.67932489 0.5        0.64450704 0.35575486]\n",
      " [0.88888889 0.53196527 0.70204082 0.32030265 0.64457143 0.14285714]\n",
      " [0.84678748 0.5518018  0.74871795 0.66234608 0.6244856  0.37453184]\n",
      " [0.81048387 0.41354071 0.71681416 0.62516734 0.64102564 0.098434  ]\n",
      " [0.85018727 0.50426687 0.76386037 0.62615741 0.65308642 0.38851351]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92358201 0.72519808 0.73434549 0.53190664 0.52519005 0.53697299]\n",
      " [0.91600336 0.78702719 0.75938697 0.58866756 0.50409013 0.62426645]\n",
      " [0.89421126 0.68959111 0.90142802 0.44050919 0.4698955  0.48447111]\n",
      " [0.85082252 0.73947674 0.85480558 0.4459282  0.34254927 0.66961123]\n",
      " [0.64818615 0.52838724 0.69760584 0.36724356 0.67193419 0.46290076]\n",
      " [0.74822367 0.56412108 0.76532737 0.42476525 0.65034466 0.50793766]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88530466 0.48050915 0.64908722 0.31644005 0.6442151  0.16759777]\n",
      " [0.87543253 0.60069686 0.68282828 0.4284153  0.6351424  0.34462445]\n",
      " [0.83895131 0.41116751 0.87943262 0.13892909 0.63015128 0.06719368]\n",
      " [0.79104478 0.52210526 0.83800623 0.61632653 0.60204579 0.47125353]\n",
      " [0.4099723  0.09237875 0.56140351 0.         0.65767045 0.00510204]\n",
      " [0.58765432 0.16240267 0.67126437 0.10510511 0.66317169 0.09223301]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.8283186  0.46841343 0.91384037 0.37381404]\n",
      " [0.4952342  0.85783669 0.66962861 0.4945379 ]\n",
      " [0.77293438 0.71240703 0.93481059 0.40060076]\n",
      " [0.63287124 0.79671694 0.92185099 0.43740942]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.81750267 0.02672606 0.89330922 0.02416918]\n",
      " [0.27768014 0.75765306 0.51308901 0.24096386]\n",
      " [0.76907426 0.49099836 0.92035398 0.07111111]\n",
      " [0.71217105 0.67       0.9081803  0.61530664]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.42374969 0.67721758 0.71749973]\n",
      " [0.60762692 0.85602365 0.4199711 ]\n",
      " [0.55212496 0.79231454 0.89411137]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61057935 0.43017657 0.59259259]\n",
      " [0.63642014 0.75418275 0.07482993]\n",
      " [0.59903382 0.64055944 0.87033748]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=2000',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92376406 0.77453951 0.60727896 0.4549584  0.32089746 0.58077723]\n",
      " [0.92302661 0.77643829 0.58273393 0.4613256  0.42142925 0.61884297]\n",
      " [0.91912223 0.74320421 0.72113436 0.42529003 0.42982807 0.60237618]\n",
      " [0.80539065 0.7382917  0.77427914 0.42783334 0.33963808 0.65292223]\n",
      " [0.78874614 0.62684993 0.80663786 0.50628041 0.56953135 0.46266826]\n",
      " [0.78299773 0.62718556 0.78644965 0.55701851 0.58382211 0.55115945]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=2000',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88571429 0.580114   0.50828729 0.17861976 0.59816691 0.26939971]\n",
      " [0.88405797 0.58181818 0.44939271 0.18893387 0.61834769 0.33128834]\n",
      " [0.87795993 0.5151751  0.64661654 0.12164074 0.62195122 0.28877005]\n",
      " [0.73611111 0.52387844 0.75780089 0.61181222 0.60252672 0.45604874]\n",
      " [0.65893271 0.28600201 0.74058577 0.39726027 0.66106443 0.00507614]\n",
      " [0.64965197 0.28657921 0.70967742 0.48402556 0.66553095 0.17551963]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.70484386 0.49400527 0.72062067 0.41724089]\n",
      " [0.70044439 0.83827252 0.73586957 0.42319415]\n",
      " [0.70953577 0.83510693 0.86100339 0.41251189]\n",
      " [0.69354095 0.83321593 0.88016908 0.49113993]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.69805527 0.07472527 0.63326653 0.1038961 ]\n",
      " [0.64981949 0.72162162 0.63181818 0.10650888]\n",
      " [0.68891281 0.717477   0.82462687 0.08682635]\n",
      " [0.71468662 0.72146119 0.85144928 0.61165049]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.69590147 0.47438076 0.78482926 0.42524718]\n",
      " [0.68203299 0.82804083 0.70392    0.41726457]\n",
      " [0.71539778 0.82569471 0.86585256 0.41308654]\n",
      " [0.67677329 0.83162762 0.89309466 0.45516352]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.6904277  0.04517454 0.71340206 0.11965812]\n",
      " [0.62034739 0.70478723 0.57627119 0.09538003]\n",
      " [0.70230608 0.70207254 0.82889734 0.08928571]\n",
      " [0.70360111 0.71899886 0.86703097 0.59873284]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.05',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.67259893 0.53340529 0.66329626 0.43379972]\n",
      " [0.68656661 0.82436285 0.71915018 0.43976579]\n",
      " [0.71407746 0.82322249 0.85463387 0.42110468]\n",
      " [0.69298568 0.83052779 0.88203765 0.47067725]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.05',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.6611399  0.16487455 0.56126482 0.13540197]\n",
      " [0.63829787 0.69853918 0.61160714 0.14040115]\n",
      " [0.69063181 0.69724771 0.81578947 0.10134128]\n",
      " [0.71785384 0.71812081 0.8545781  0.60415557]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.48816501 0.68615569 0.63757079]\n",
      " [0.54501676 0.82016141 0.38662337]\n",
      " [0.54450512 0.81743423 0.82244834]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61381896 0.4789357  0.50328228]\n",
      " [0.60541814 0.69200524 0.01403509]\n",
      " [0.58643861 0.68692206 0.78136201]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.45625321 0.71602369 0.63226122]\n",
      " [0.53506335 0.82626575 0.38662337]\n",
      " [0.54685224 0.81112493 0.82115385]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.60751566 0.52702703 0.50107066]\n",
      " [0.60081823 0.70298314 0.01403509]\n",
      " [0.59038344 0.67631579 0.78321678]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.05',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.48816501 0.68615569 0.63757079]\n",
      " [0.54099087 0.8195464  0.38662337]\n",
      " [0.54403083 0.81523684 0.8182044 ]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.05',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61381896 0.4789357  0.50328228]\n",
      " [0.61325648 0.69047619 0.01403509]\n",
      " [0.59178744 0.68266667 0.7763864 ]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1000',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92138169 0.77264977 0.61785761 0.46422801 0.32808658 0.58657674]\n",
      " [0.92283835 0.77968542 0.61950314 0.46874297 0.39542424 0.61470317]\n",
      " [0.91560444 0.75180779 0.69891668 0.4591756  0.37116834 0.6133069 ]\n",
      " [0.86790959 0.76016456 0.77535217 0.47639172 0.33307381 0.68414945]\n",
      " [0.73107286 0.61431797 0.80402404 0.48988766 0.56619844 0.46504185]\n",
      " [0.73414328 0.62158688 0.80000737 0.52464719 0.5850042  0.66270962]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1000',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88214286 0.57697121 0.52205882 0.19544846 0.59922556 0.28075253]\n",
      " [0.88363636 0.5885451  0.51153846 0.20293725 0.61269365 0.32634731]\n",
      " [0.87272727 0.53323594 0.62385321 0.18281037 0.60740741 0.31385643]\n",
      " [0.81072555 0.55767077 0.74440895 0.61611374 0.60038797 0.47905478]\n",
      " [0.55860349 0.26131687 0.73572939 0.45007236 0.66109253 0.01007557]\n",
      " [0.56435644 0.27593152 0.72921109 0.54684512 0.66704481 0.39325843]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92138169 0.77264977 0.61785761 0.46422801 0.32808658 0.58657674]\n",
      " [0.92283835 0.77968542 0.61950314 0.46874297 0.39542424 0.61470317]\n",
      " [0.91560444 0.75180779 0.69891668 0.4591756  0.37116834 0.6133069 ]\n",
      " [0.86790959 0.76016456 0.77535217 0.47639172 0.33307381 0.68414945]\n",
      " [0.73107286 0.61431797 0.80402404 0.48988766 0.56619844 0.46504185]\n",
      " [0.73414328 0.62158688 0.80000737 0.52464719 0.5850042  0.66270962]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88214286 0.57697121 0.52205882 0.19544846 0.59922556 0.28075253]\n",
      " [0.88363636 0.5885451  0.51153846 0.20293725 0.61269365 0.32634731]\n",
      " [0.87272727 0.53323594 0.62385321 0.18281037 0.60740741 0.31385643]\n",
      " [0.81072555 0.55767077 0.74440895 0.61611374 0.60038797 0.47905478]\n",
      " [0.55860349 0.26131687 0.73572939 0.45007236 0.66109253 0.01007557]\n",
      " [0.56435644 0.27593152 0.72921109 0.54684512 0.66704481 0.39325843]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.67259893 0.53340529 0.66329626 0.43379972]\n",
      " [0.41100434 0.83135154 0.38280195 0.4100265 ]\n",
      " [0.64892101 0.84054054 0.82960994 0.49589154]\n",
      " [0.62808138 0.81618581 0.83108059 0.4637662 ]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.6611399  0.16487455 0.56126482 0.13540197]\n",
      " [0.12180747 0.71028037 0.00704225 0.07902736]\n",
      " [0.64365482 0.73333333 0.78994614 0.24736842]\n",
      " [0.67085202 0.69821241 0.80199667 0.60506864]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.87663175 0.67309736 0.56528696 0.39209292 0.64521277 0.52560417]\n",
      " [0.86237784 0.69471743 0.52378333 0.3826947  0.65136698 0.52699601]\n",
      " [0.87042244 0.70386502 0.8376986  0.40192466 0.5214309  0.5183276 ]\n",
      " [0.7054884  0.65323336 0.77130647 0.40429695 0.36065463 0.54326677]\n",
      " [0.66552828 0.57925205 0.80089384 0.37017859 0.58257789 0.46197047]\n",
      " [0.68837009 0.5948286  0.78829343 0.39029428 0.59367213 0.70508986]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.80943026 0.37842617 0.34972678 0.04900459 0.6375     0.14787431]\n",
      " [0.78642715 0.41926851 0.27058824 0.03100775 0.6163142  0.14342629]\n",
      " [0.80505415 0.44       0.80483592 0.06917293 0.64432432 0.13407821]\n",
      " [0.63805104 0.39331709 0.76815642 0.60657371 0.60822723 0.36797066]\n",
      " [0.44204852 0.19243243 0.72766885 0.00631912 0.66056096 0.005     ]\n",
      " [0.48293963 0.22292994 0.70693512 0.04334365 0.66240558 0.47227191]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88473193 0.67724787 0.52762378 0.39405075 0.63839072 0.57012033]\n",
      " [0.88442159 0.67586855 0.51984127 0.39405075 0.63435599 0.56139722]\n",
      " [0.88495978 0.69311479 0.62488773 0.41418566 0.63926614 0.60883764]\n",
      " [0.88180836 0.71164535 0.70976075 0.51323608 0.62193603 0.6642082 ]\n",
      " [0.88193202 0.70875035 0.64901482 0.46093306 0.64786315 0.63470096]\n",
      " [0.88270384 0.70336233 0.6503081  0.45236263 0.64387382 0.64009238]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82307692 0.386121   0.27647059 0.05206738 0.59908537 0.22718808]\n",
      " [0.82239382 0.38301716 0.26190476 0.05206738 0.58914729 0.20952381]\n",
      " [0.82527881 0.41833333 0.45128205 0.09411765 0.63902107 0.30990415]\n",
      " [0.82630691 0.46092184 0.60262009 0.30963303 0.66585514 0.43857635]\n",
      " [0.82289803 0.45       0.49382716 0.19337748 0.65695364 0.36571429]\n",
      " [0.82374101 0.43933386 0.49376559 0.1754386  0.65113182 0.37317784]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1500_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88569286 0.67321546 0.51525863 0.39165879 0.65222755 0.51984847]\n",
      " [0.87704828 0.67212253 0.51424056 0.38999222 0.65027223 0.52155866]\n",
      " [0.88473193 0.68246811 0.56365464 0.40418518 0.65472147 0.53706578]\n",
      " [0.89392963 0.6993021  0.62717756 0.45465146 0.63816948 0.55968973]\n",
      " [0.8931184  0.69440493 0.61251778 0.44641694 0.64468124 0.55479872]\n",
      " [0.89175106 0.69337215 0.6124726  0.44532582 0.64538043 0.5552965 ]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1500_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82352941 0.37793852 0.26086957 0.0462963  0.60143198 0.13409962]\n",
      " [0.80952381 0.37545788 0.25730994 0.04327666 0.59301381 0.13592233]\n",
      " [0.82307692 0.39688042 0.35449735 0.06990881 0.63759828 0.17421603]\n",
      " [0.83918669 0.43152866 0.46746988 0.17015342 0.65045992 0.22734255]\n",
      " [0.83738318 0.42131148 0.44226044 0.15319149 0.64733648 0.2144    ]\n",
      " [0.83520599 0.41914191 0.44059406 0.15078236 0.64538043 0.21393841]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=500_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.89195931 0.68406743 0.48778038 0.40970502 0.65667169 0.54022187]\n",
      " [0.88792286 0.67649577 0.47175176 0.40127813 0.65302103 0.53126891]\n",
      " [0.88560319 0.70336894 0.61598315 0.4555902  0.62222384 0.57611358]\n",
      " [0.86951447 0.70747663 0.70468423 0.56730425 0.56696476 0.64043603]\n",
      " [0.8903296  0.69087945 0.55985743 0.50276943 0.65348079 0.55119621]\n",
      " [0.89253701 0.69230909 0.55985743 0.50471102 0.65416583 0.56279175]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=500_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.83397683 0.39892665 0.20062696 0.08797654 0.63311451 0.1659919 ]\n",
      " [0.82677165 0.38398544 0.17197452 0.06896552 0.61954887 0.14675052]\n",
      " [0.82758621 0.43890675 0.43085106 0.19010417 0.66174662 0.24482759]\n",
      " [0.81045752 0.45425049 0.58468677 0.48474856 0.65345413 0.38610039]\n",
      " [0.83206107 0.41258741 0.32947977 0.28019324 0.65771812 0.187251  ]\n",
      " [0.83524904 0.41535777 0.32947977 0.28399519 0.65815984 0.20907298]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.9217285  0.73948689 0.72243176 0.49016739 0.54105049 0.52891525]\n",
      " [0.92430122 0.77920772 0.75515393 0.61983921 0.53788623 0.64568391]\n",
      " [0.92693988 0.75733938 0.76838932 0.5203117  0.5503073  0.57345634]\n",
      " [0.90080858 0.76041018 0.80432691 0.68144866 0.42569937 0.66809539]\n",
      " [0.90260652 0.71188622 0.7986447  0.64155443 0.63056017 0.54939525]\n",
      " [0.91650241 0.75389011 0.82715462 0.58138211 0.58690131 0.6832274 ]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88203267 0.50786164 0.62761506 0.24052288 0.64487535 0.15151515]\n",
      " [0.8869258  0.58688303 0.66949153 0.48390447 0.64305479 0.38718663]\n",
      " [0.88929889 0.54192547 0.69022869 0.29118774 0.64104014 0.23655914]\n",
      " [0.8557377  0.55816555 0.76740238 0.64723468 0.61960386 0.44470046]\n",
      " [0.84990253 0.452732   0.72570194 0.632946   0.64486593 0.17991632]\n",
      " [0.8738574  0.53687316 0.7704918  0.63807286 0.64976415 0.44341085]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82635386 0.4741533  0.91066814 0.38561495]\n",
      " [0.78269461 0.8508026  0.87995337 0.51911164]\n",
      " [0.78738    0.83066357 0.93596498 0.4870938 ]\n",
      " [0.73035258 0.81316128 0.92937    0.48696865]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.81576145 0.03921569 0.88888889 0.04747774]\n",
      " [0.76031215 0.74689826 0.84555985 0.29839704]\n",
      " [0.77589852 0.71018277 0.92114695 0.23560209]\n",
      " [0.71713985 0.6856465  0.91448517 0.62421053]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82635386 0.4741533  0.91066814 0.38561495]\n",
      " [0.83661713 0.84552568 0.89459995 0.52446432]\n",
      " [0.80096822 0.839491   0.93014361 0.49581838]\n",
      " [0.76199143 0.83571764 0.95083965 0.4755648 ]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.81576145 0.03921569 0.88888889 0.04747774]\n",
      " [0.8215859  0.7378882  0.86629002 0.30937881]\n",
      " [0.78663793 0.72704403 0.91397849 0.25129534]\n",
      " [0.76056338 0.7258248  0.94014085 0.6218049 ]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.05',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82635386 0.4741533  0.91066814 0.38561495]\n",
      " [0.86200297 0.8459884  0.90255668 0.49884869]\n",
      " [0.79886617 0.84783586 0.93887566 0.49711586]\n",
      " [0.78069978 0.82871599 0.94942549 0.47846107]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.05',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.81576145 0.03921569 0.88888889 0.04747774]\n",
      " [0.85027322 0.73803526 0.87732342 0.2638191 ]\n",
      " [0.77814939 0.73997413 0.92473118 0.25355757]\n",
      " [0.77258567 0.71046229 0.93848858 0.6190226 ]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.40038554 0.69094953 0.79526454]\n",
      " [0.476151   0.84913661 0.46507546]\n",
      " [0.52185359 0.81564444 0.88292683]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.01',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.60319043 0.47583643 0.71714922]\n",
      " [0.61384046 0.74481074 0.15635179]\n",
      " [0.6031927  0.6848249  0.85454545]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.40038554 0.69094953 0.79526454]\n",
      " [0.43811876 0.84620236 0.46172535]\n",
      " [0.53194564 0.84021605 0.87965456]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.60319043 0.47583643 0.71714922]\n",
      " [0.60829493 0.73955774 0.1503268 ]\n",
      " [0.61781285 0.72773537 0.84981685]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.05',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.44394952 0.6644884  0.52044037]\n",
      " [0.43849709 0.85783706 0.40905902]\n",
      " [0.50245324 0.84912849 0.88466239]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.05',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61569827 0.4040404  0.25688073]\n",
      " [0.61342828 0.75792142 0.05498282]\n",
      " [0.61596958 0.74263764 0.85447761]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dfs_cl = []\n",
    "for df in csvs:\n",
    "    df_cl_metrics = transform_df_to_cl_metrics(df, \n",
    "                                zero_shots, \n",
    "                                performance_column=\"f1_score\", \n",
    "                                experiment_name_column=\"experiment_name\", \n",
    "                                dataset_test_results_column=\"dataset_currently_testing\", \n",
    "                                dataset_current_training_column=\"dataset_currently_training\", \n",
    "                                time_column=\"time\",\n",
    "                                model_name_column=\"model\", \n",
    "                                dataset_dict_trainings=dict_name_experiments_domain_transfer)\n",
    "    dfs_cl.append(df_cl_metrics)\n",
    "\n",
    "    df_cl_metrics = transform_df_to_cl_metrics(df, \n",
    "                                zero_shots, \n",
    "                                performance_column=\"HATE_f1_score\", \n",
    "                                experiment_name_column=\"experiment_name\", \n",
    "                                dataset_test_results_column=\"dataset_currently_testing\", \n",
    "                                dataset_current_training_column=\"dataset_currently_training\", \n",
    "                                time_column=\"time\",\n",
    "                                model_name_column=\"model\", \n",
    "                                dataset_dict_trainings=dict_name_experiments_domain_transfer)\n",
    "    dfs_cl.append(df_cl_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_cl = pd.concat(dfs_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cl_technique</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>time</th>\n",
       "      <th>best_epochs</th>\n",
       "      <th>current_num_samples_training</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>last</th>\n",
       "      <th>avg_incremental_f1</th>\n",
       "      <th>transfer</th>\n",
       "      <th>bwt</th>\n",
       "      <th>fw_transfer</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.715044</td>\n",
       "      <td>0.800792</td>\n",
       "      <td>0.810066</td>\n",
       "      <td>-0.028600</td>\n",
       "      <td>0.384275</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.631012</td>\n",
       "      <td>0.715327</td>\n",
       "      <td>0.726103</td>\n",
       "      <td>-0.012303</td>\n",
       "      <td>0.016875</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.610120</td>\n",
       "      <td>0.753176</td>\n",
       "      <td>0.742770</td>\n",
       "      <td>-0.115424</td>\n",
       "      <td>0.331506</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.380305</td>\n",
       "      <td>0.624947</td>\n",
       "      <td>0.584280</td>\n",
       "      <td>-0.289967</td>\n",
       "      <td>-0.047323</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.724843</td>\n",
       "      <td>0.806614</td>\n",
       "      <td>0.817026</td>\n",
       "      <td>-0.023101</td>\n",
       "      <td>0.383406</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.652078</td>\n",
       "      <td>0.724422</td>\n",
       "      <td>0.737754</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.024406</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.697212</td>\n",
       "      <td>0.752196</td>\n",
       "      <td>0.673906</td>\n",
       "      <td>-0.089842</td>\n",
       "      <td>0.192246</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.726414</td>\n",
       "      <td>0.697098</td>\n",
       "      <td>0.557056</td>\n",
       "      <td>-0.068386</td>\n",
       "      <td>-0.437628</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.739963</td>\n",
       "      <td>0.808600</td>\n",
       "      <td>0.805337</td>\n",
       "      <td>-0.046746</td>\n",
       "      <td>0.293099</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.735371</td>\n",
       "      <td>0.776787</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>-0.055512</td>\n",
       "      <td>-0.267811</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.756028</td>\n",
       "      <td>0.820080</td>\n",
       "      <td>0.835454</td>\n",
       "      <td>-0.017825</td>\n",
       "      <td>0.300889</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.762083</td>\n",
       "      <td>0.791701</td>\n",
       "      <td>0.795757</td>\n",
       "      <td>-0.013700</td>\n",
       "      <td>-0.255669</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.05</td>\n",
       "      <td>0.759326</td>\n",
       "      <td>0.825384</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>-0.017459</td>\n",
       "      <td>0.303974</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.05</td>\n",
       "      <td>0.760140</td>\n",
       "      <td>0.796085</td>\n",
       "      <td>0.805505</td>\n",
       "      <td>-0.018997</td>\n",
       "      <td>-0.251238</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.746184</td>\n",
       "      <td>0.633920</td>\n",
       "      <td>0.639923</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.281928</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.703310</td>\n",
       "      <td>0.669730</td>\n",
       "      <td>0.628108</td>\n",
       "      <td>-0.062584</td>\n",
       "      <td>-0.280830</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.740142</td>\n",
       "      <td>0.601057</td>\n",
       "      <td>0.572450</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>0.311346</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.714188</td>\n",
       "      <td>0.665568</td>\n",
       "      <td>0.628925</td>\n",
       "      <td>-0.029992</td>\n",
       "      <td>-0.217239</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.750605</td>\n",
       "      <td>0.597717</td>\n",
       "      <td>0.562100</td>\n",
       "      <td>0.062787</td>\n",
       "      <td>0.309671</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.731788</td>\n",
       "      <td>0.669635</td>\n",
       "      <td>0.640535</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>-0.220252</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.05</td>\n",
       "      <td>0.745415</td>\n",
       "      <td>0.612510</td>\n",
       "      <td>0.557144</td>\n",
       "      <td>0.024898</td>\n",
       "      <td>0.270107</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.05</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>0.679689</td>\n",
       "      <td>0.646366</td>\n",
       "      <td>-0.007506</td>\n",
       "      <td>-0.303822</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.626758</td>\n",
       "      <td>0.719867</td>\n",
       "      <td>0.714917</td>\n",
       "      <td>-0.068093</td>\n",
       "      <td>0.085761</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.431804</td>\n",
       "      <td>0.589118</td>\n",
       "      <td>0.554925</td>\n",
       "      <td>-0.236423</td>\n",
       "      <td>0.124744</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>mas</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mas_lambda=1000_mas_variation=global</td>\n",
       "      <td>0.662117</td>\n",
       "      <td>0.739188</td>\n",
       "      <td>0.756575</td>\n",
       "      <td>-0.002795</td>\n",
       "      <td>0.175057</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>mas</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mas_lambda=1000_mas_variation=global</td>\n",
       "      <td>0.492765</td>\n",
       "      <td>0.592799</td>\n",
       "      <td>0.616171</td>\n",
       "      <td>-0.008110</td>\n",
       "      <td>0.213204</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>mas</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mas_lambda=1500_mas_variation=global</td>\n",
       "      <td>0.640600</td>\n",
       "      <td>0.723026</td>\n",
       "      <td>0.744012</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.158397</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>mas</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mas_lambda=1500_mas_variation=global</td>\n",
       "      <td>0.450841</td>\n",
       "      <td>0.561510</td>\n",
       "      <td>0.592131</td>\n",
       "      <td>0.024026</td>\n",
       "      <td>0.172465</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>mas</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mas_lambda=500_mas_variation=global</td>\n",
       "      <td>0.644395</td>\n",
       "      <td>0.737543</td>\n",
       "      <td>0.752928</td>\n",
       "      <td>-0.020329</td>\n",
       "      <td>0.147389</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GroNLP/hateBERT</td>\n",
       "      <td>mas</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mas_lambda=500_mas_variation=global</td>\n",
       "      <td>0.455219</td>\n",
       "      <td>0.591050</td>\n",
       "      <td>0.608902</td>\n",
       "      <td>-0.053808</td>\n",
       "      <td>0.178804</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.689828</td>\n",
       "      <td>0.772114</td>\n",
       "      <td>0.780307</td>\n",
       "      <td>-0.012517</td>\n",
       "      <td>-0.016585</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.557072</td>\n",
       "      <td>0.675327</td>\n",
       "      <td>0.664791</td>\n",
       "      <td>-0.100727</td>\n",
       "      <td>-0.097381</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>ewc</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>ewc_lambda=2000</td>\n",
       "      <td>0.648106</td>\n",
       "      <td>0.760358</td>\n",
       "      <td>0.775293</td>\n",
       "      <td>-0.016246</td>\n",
       "      <td>-0.028639</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>ewc</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>ewc_lambda=2000</td>\n",
       "      <td>0.495164</td>\n",
       "      <td>0.666651</td>\n",
       "      <td>0.666602</td>\n",
       "      <td>-0.118312</td>\n",
       "      <td>-0.107844</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>ewc</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>ewc_lambda=1000</td>\n",
       "      <td>0.654683</td>\n",
       "      <td>0.762860</td>\n",
       "      <td>0.774118</td>\n",
       "      <td>-0.035437</td>\n",
       "      <td>-0.015725</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>ewc</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>ewc_lambda=1000</td>\n",
       "      <td>0.529441</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.669799</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>-0.083237</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>ewc</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>ewc_lambda=1500</td>\n",
       "      <td>0.654683</td>\n",
       "      <td>0.762860</td>\n",
       "      <td>0.774118</td>\n",
       "      <td>-0.035437</td>\n",
       "      <td>-0.015725</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>ewc</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>ewc_lambda=1500</td>\n",
       "      <td>0.529441</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.669799</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>-0.083237</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.724516</td>\n",
       "      <td>0.750150</td>\n",
       "      <td>0.758358</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>-0.070255</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.724812</td>\n",
       "      <td>0.713065</td>\n",
       "      <td>0.705182</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>-0.279311</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.714165</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>0.751026</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>-0.087255</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.722091</td>\n",
       "      <td>0.704878</td>\n",
       "      <td>0.695249</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-0.306857</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.05</td>\n",
       "      <td>0.719057</td>\n",
       "      <td>0.736108</td>\n",
       "      <td>0.752356</td>\n",
       "      <td>0.017985</td>\n",
       "      <td>-0.059830</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.05</td>\n",
       "      <td>0.723677</td>\n",
       "      <td>0.696948</td>\n",
       "      <td>0.698585</td>\n",
       "      <td>0.038361</td>\n",
       "      <td>-0.251160</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.684778</td>\n",
       "      <td>0.687895</td>\n",
       "      <td>0.638061</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>-0.147017</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>evalita-TO-waseem-racism-TO-ibereval-TO-hateva...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.694032</td>\n",
       "      <td>0.623382</td>\n",
       "      <td>0.511330</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>-0.404006</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.712936</td>\n",
       "      <td>0.623504</td>\n",
       "      <td>0.595974</td>\n",
       "      <td>0.019187</td>\n",
       "      <td>-0.174450</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.676758</td>\n",
       "      <td>0.626632</td>\n",
       "      <td>0.564453</td>\n",
       "      <td>-0.011815</td>\n",
       "      <td>-0.337368</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.728129</td>\n",
       "      <td>0.632961</td>\n",
       "      <td>0.612993</td>\n",
       "      <td>0.026806</td>\n",
       "      <td>-0.172539</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.684908</td>\n",
       "      <td>0.649146</td>\n",
       "      <td>0.621049</td>\n",
       "      <td>-0.016232</td>\n",
       "      <td>-0.333872</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.726377</td>\n",
       "      <td>0.621098</td>\n",
       "      <td>0.607026</td>\n",
       "      <td>0.037729</td>\n",
       "      <td>-0.157605</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.01</td>\n",
       "      <td>0.683305</td>\n",
       "      <td>0.647574</td>\n",
       "      <td>0.617084</td>\n",
       "      <td>-0.021900</td>\n",
       "      <td>-0.309826</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.05</td>\n",
       "      <td>0.725824</td>\n",
       "      <td>0.631419</td>\n",
       "      <td>0.610312</td>\n",
       "      <td>0.025778</td>\n",
       "      <td>-0.172539</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>agem</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.05</td>\n",
       "      <td>0.683614</td>\n",
       "      <td>0.649766</td>\n",
       "      <td>0.625242</td>\n",
       "      <td>-0.014921</td>\n",
       "      <td>-0.333872</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model cl_technique  \\\n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base   vanilla_ft   \n",
       "0  FacebookAI/roberta-base   vanilla_ft   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base   vanilla_ft   \n",
       "0  FacebookAI/roberta-base   vanilla_ft   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base   vanilla_ft   \n",
       "0  FacebookAI/roberta-base   vanilla_ft   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0  FacebookAI/roberta-base         agem   \n",
       "0          GroNLP/hateBERT   vanilla_ft   \n",
       "0          GroNLP/hateBERT   vanilla_ft   \n",
       "0          GroNLP/hateBERT          mas   \n",
       "0          GroNLP/hateBERT          mas   \n",
       "0          GroNLP/hateBERT          mas   \n",
       "0          GroNLP/hateBERT          mas   \n",
       "0          GroNLP/hateBERT          mas   \n",
       "0          GroNLP/hateBERT          mas   \n",
       "0            diptanu/fBERT   vanilla_ft   \n",
       "0            diptanu/fBERT   vanilla_ft   \n",
       "0            diptanu/fBERT          ewc   \n",
       "0            diptanu/fBERT          ewc   \n",
       "0            diptanu/fBERT          ewc   \n",
       "0            diptanu/fBERT          ewc   \n",
       "0            diptanu/fBERT          ewc   \n",
       "0            diptanu/fBERT          ewc   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT   vanilla_ft   \n",
       "0            diptanu/fBERT   vanilla_ft   \n",
       "0            diptanu/fBERT   vanilla_ft   \n",
       "0            diptanu/fBERT   vanilla_ft   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "0            diptanu/fBERT         agem   \n",
       "\n",
       "                                     experiment_name  time  best_epochs  \\\n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0  evalita-TO-waseem-racism-TO-ibereval-TO-hateva...     3            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0     hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "\n",
       "   current_num_samples_training  learning_rate  \\\n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4293        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4799        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "0                          4500        0.00001   \n",
       "\n",
       "                            hyperparams      last  avg_incremental_f1  \\\n",
       "0              mem_size_proportion=0.01  0.715044            0.800792   \n",
       "0              mem_size_proportion=0.01  0.631012            0.715327   \n",
       "0                                        0.610120            0.753176   \n",
       "0                                        0.380305            0.624947   \n",
       "0             mem_size_proportion=0.025  0.724843            0.806614   \n",
       "0             mem_size_proportion=0.025  0.652078            0.724422   \n",
       "0                                        0.697212            0.752196   \n",
       "0                                        0.726414            0.697098   \n",
       "0              mem_size_proportion=0.01  0.739963            0.808600   \n",
       "0              mem_size_proportion=0.01  0.735371            0.776787   \n",
       "0             mem_size_proportion=0.025  0.756028            0.820080   \n",
       "0             mem_size_proportion=0.025  0.762083            0.791701   \n",
       "0              mem_size_proportion=0.05  0.759326            0.825384   \n",
       "0              mem_size_proportion=0.05  0.760140            0.796085   \n",
       "0                                        0.746184            0.633920   \n",
       "0                                        0.703310            0.669730   \n",
       "0              mem_size_proportion=0.01  0.740142            0.601057   \n",
       "0              mem_size_proportion=0.01  0.714188            0.665568   \n",
       "0             mem_size_proportion=0.025  0.750605            0.597717   \n",
       "0             mem_size_proportion=0.025  0.731788            0.669635   \n",
       "0              mem_size_proportion=0.05  0.745415            0.612510   \n",
       "0              mem_size_proportion=0.05  0.737695            0.679689   \n",
       "0                                        0.626758            0.719867   \n",
       "0                                        0.431804            0.589118   \n",
       "0  mas_lambda=1000_mas_variation=global  0.662117            0.739188   \n",
       "0  mas_lambda=1000_mas_variation=global  0.492765            0.592799   \n",
       "0  mas_lambda=1500_mas_variation=global  0.640600            0.723026   \n",
       "0  mas_lambda=1500_mas_variation=global  0.450841            0.561510   \n",
       "0   mas_lambda=500_mas_variation=global  0.644395            0.737543   \n",
       "0   mas_lambda=500_mas_variation=global  0.455219            0.591050   \n",
       "0                                        0.689828            0.772114   \n",
       "0                                        0.557072            0.675327   \n",
       "0                       ewc_lambda=2000  0.648106            0.760358   \n",
       "0                       ewc_lambda=2000  0.495164            0.666651   \n",
       "0                       ewc_lambda=1000  0.654683            0.762860   \n",
       "0                       ewc_lambda=1000  0.529441            0.673312   \n",
       "0                       ewc_lambda=1500  0.654683            0.762860   \n",
       "0                       ewc_lambda=1500  0.529441            0.673312   \n",
       "0             mem_size_proportion=0.025  0.724516            0.750150   \n",
       "0             mem_size_proportion=0.025  0.724812            0.713065   \n",
       "0              mem_size_proportion=0.01  0.714165            0.741855   \n",
       "0              mem_size_proportion=0.01  0.722091            0.704878   \n",
       "0              mem_size_proportion=0.05  0.719057            0.736108   \n",
       "0              mem_size_proportion=0.05  0.723677            0.696948   \n",
       "0                                        0.684778            0.687895   \n",
       "0                                        0.694032            0.623382   \n",
       "0                                        0.712936            0.623504   \n",
       "0                                        0.676758            0.626632   \n",
       "0             mem_size_proportion=0.025  0.728129            0.632961   \n",
       "0             mem_size_proportion=0.025  0.684908            0.649146   \n",
       "0              mem_size_proportion=0.01  0.726377            0.621098   \n",
       "0              mem_size_proportion=0.01  0.683305            0.647574   \n",
       "0              mem_size_proportion=0.05  0.725824            0.631419   \n",
       "0              mem_size_proportion=0.05  0.683614            0.649766   \n",
       "\n",
       "   transfer       bwt  fw_transfer         metric  \n",
       "0  0.810066 -0.028600     0.384275       f1_score  \n",
       "0  0.726103 -0.012303     0.016875  HATE_f1_score  \n",
       "0  0.742770 -0.115424     0.331506       f1_score  \n",
       "0  0.584280 -0.289967    -0.047323  HATE_f1_score  \n",
       "0  0.817026 -0.023101     0.383406       f1_score  \n",
       "0  0.737754  0.003563     0.024406  HATE_f1_score  \n",
       "0  0.673906 -0.089842     0.192246       f1_score  \n",
       "0  0.557056 -0.068386    -0.437628  HATE_f1_score  \n",
       "0  0.805337 -0.046746     0.293099       f1_score  \n",
       "0  0.758592 -0.055512    -0.267811  HATE_f1_score  \n",
       "0  0.835454 -0.017825     0.300889       f1_score  \n",
       "0  0.795757 -0.013700    -0.255669  HATE_f1_score  \n",
       "0  0.846100 -0.017459     0.303974       f1_score  \n",
       "0  0.805505 -0.018997    -0.251238  HATE_f1_score  \n",
       "0  0.639923  0.032333     0.281928       f1_score  \n",
       "0  0.628108 -0.062584    -0.280830  HATE_f1_score  \n",
       "0  0.572450  0.043988     0.311346       f1_score  \n",
       "0  0.628925 -0.029992    -0.217239  HATE_f1_score  \n",
       "0  0.562100  0.062787     0.309671       f1_score  \n",
       "0  0.640535  0.001400    -0.220252  HATE_f1_score  \n",
       "0  0.557144  0.024898     0.270107       f1_score  \n",
       "0  0.646366 -0.007506    -0.303822  HATE_f1_score  \n",
       "0  0.714917 -0.068093     0.085761       f1_score  \n",
       "0  0.554925 -0.236423     0.124744  HATE_f1_score  \n",
       "0  0.756575 -0.002795     0.175057       f1_score  \n",
       "0  0.616171 -0.008110     0.213204  HATE_f1_score  \n",
       "0  0.744012  0.013500     0.158397       f1_score  \n",
       "0  0.592131  0.024026     0.172465  HATE_f1_score  \n",
       "0  0.752928 -0.020329     0.147389       f1_score  \n",
       "0  0.608902 -0.053808     0.178804  HATE_f1_score  \n",
       "0  0.780307 -0.012517    -0.016585       f1_score  \n",
       "0  0.664791 -0.100727    -0.097381  HATE_f1_score  \n",
       "0  0.775293 -0.016246    -0.028639       f1_score  \n",
       "0  0.666602 -0.118312    -0.107844  HATE_f1_score  \n",
       "0  0.774118 -0.035437    -0.015725       f1_score  \n",
       "0  0.669799 -0.117672    -0.083237  HATE_f1_score  \n",
       "0  0.774118 -0.035437    -0.015725       f1_score  \n",
       "0  0.669799 -0.117672    -0.083237  HATE_f1_score  \n",
       "0  0.758358  0.000935    -0.070255       f1_score  \n",
       "0  0.705182  0.014431    -0.279311  HATE_f1_score  \n",
       "0  0.751026  0.003900    -0.087255       f1_score  \n",
       "0  0.695249  0.021840    -0.306857  HATE_f1_score  \n",
       "0  0.752356  0.017985    -0.059830       f1_score  \n",
       "0  0.698585  0.038361    -0.251160  HATE_f1_score  \n",
       "0  0.638061 -0.019404    -0.147017       f1_score  \n",
       "0  0.511330  0.003232    -0.404006  HATE_f1_score  \n",
       "0  0.595974  0.019187    -0.174450       f1_score  \n",
       "0  0.564453 -0.011815    -0.337368  HATE_f1_score  \n",
       "0  0.612993  0.026806    -0.172539       f1_score  \n",
       "0  0.621049 -0.016232    -0.333872  HATE_f1_score  \n",
       "0  0.607026  0.037729    -0.157605       f1_score  \n",
       "0  0.617084 -0.021900    -0.309826  HATE_f1_score  \n",
       "0  0.610312  0.025778    -0.172539       f1_score  \n",
       "0  0.625242 -0.014921    -0.333872  HATE_f1_score  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_cl.sort_values([\"model\", \"experiment_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_cl.to_csv(\"df_cl_metrics_hyperparams.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
