{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_exclude = [\"predictions\", \"labels\", \"generations\", \"unfiltered_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diptanu-fBERT_SEQ_CLS_VANILLA_FT_davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism__RESULTS.json\n",
      "diptanu-fBERT_SEQ_CLS_VANILLA_FT_evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant__RESULTS.json\n",
      "diptanu-fBERT_SEQ_CLS_VANILLA_FT_hateval-immigrant-TO-waseem-racism-TO-ibereval__RESULTS.json\n",
      "FacebookAI-roberta-base_SEQ_CLS_VANILLA_FT_davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism__RESULTS.json\n",
      "FacebookAI-roberta-base_SEQ_CLS_VANILLA_FT_evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant__RESULTS.json\n",
      "FacebookAI-roberta-base_SEQ_CLS_VANILLA_FT_hateval-immigrant-TO-waseem-racism-TO-ibereval__RESULTS.json\n",
      "fBERT_AGEM_davidson_mem_size_proportion0025_RESULTS.json\n",
      "fBERT_AGEM_evalita-proportion0025_RESULTS.json\n",
      "fBERT_AGEM_hatevalmem_size_proportion0025_RESULTS.json\n",
      "fBERT_EWC_davidson_ewc_lambda1500_RESULTS.json\n",
      "fBERT_EWC_evalita-TO-waseem_lambda1500_RESULTS.json\n",
      "fBERT_EWC_hateval_ewc_lambda1500_RESULTS.json\n",
      "fBERT_LWF_davidson_lwf_lambda1_temperature2_RESULTS.json\n",
      "fBERT_LWF_evalita_lwf_lambda=1_temperature=2_RESULTS.json\n",
      "fBERT_LWF_hateval_lwf_lambda1temperature2_RESULTS.json\n",
      "fBERT_MAS_davidson_mas_lambda1000_RESULTS.json\n",
      "fBERT_MAS_evalita-mas_lambda1000_RESULTS.json\n",
      "fBERT_MAS_hateval_mas_lambda1000_RESULTS.json\n",
      "GroNLP-hateBERT_EWC_evalita-ewc_lambda1500_RESULTS.json\n",
      "GroNLP-hateBERT_SEQ_CLS_VANILLA_FT_davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism__RESULTS.json\n",
      "GroNLP-hateBERT_SEQ_CLS_VANILLA_FT_evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant__RESULTS.json\n",
      "GroNLP-hateBERT_SEQ_CLS_VANILLA_FT_hateval-immigrant-TO-waseem-racism-TO-ibereval__RESULTS.json\n",
      "hateBERT_AGEM_davidson_mem_size_proportion0025_RESULTS.json\n",
      "hateBERT_AGEM_evalita_mem_size_proportion0025_RESULTS.json\n",
      "hateBERT_AGEM_hateval_mem_size_proportion0025_RESULTS.json\n",
      "hateBERT_EWC_hateval_ewc_lambda1500_RESULTS.json\n",
      "hateBERT_LWF_davidson_lwf_lambda=1_temperature=2_RESULTS.json\n",
      "hateBERT_LWF_evalita_lwf_lambda1_temperature2_RESULTS.json\n",
      "hateBERT_LWF_hateval_lwf_lambda=1_temperature=2_RESULTS.json\n",
      "hateBERT_MAS_davidson_mas_lambd=1000_RESULTS.json\n",
      "hateBERT_MAS_hateval_mas_lambda1000_RESULTS.json\n",
      "hateBERT_SEQ_CLS_EWC_davidson_ewc_lambda1500_RESULTS.json\n",
      "hateBERT__MAS_evalita_mas_lambda1000_RESULTS.json\n",
      "roberta-base_AGEM_davidson_mem_size_proportion0025_RESULTS.json\n",
      "roberta-base_AGEM_evalita_mem_size_proportion0025_RESULTS.json\n",
      "roberta-base_AGEM_hateval_mem_size_proportion0025_RESULTS.json\n",
      "roberta-base_EWC_davidson_ewc_lambda1500_RESULTS.json\n",
      "roberta-base_EWC_evalita_ewc_lambda1500_RESULTS.json\n",
      "roberta-base_EWC_hateval_ewc_lambda1500_RESULTS.json\n",
      "roberta-base_LWF_davidson_lwf_lambda1_temperature2_RESULTS.json\n",
      "roberta-base_LWF_evalita_lwf_lambda1_temperature2_RESULTS.json\n",
      "roberta-base_LWF_hateval_lwf_lambda1temperature2_RESULTS.json\n",
      "roberta-base_MAS_davidson_mas_lambda1000_RESULTS.json\n",
      "roberta-base_MAS_evalita_mas_lambda=1000_RESULTS.json\n",
      "roberta-base_MAS_hateval_mas_lambda1000_RESULTS.json\n"
     ]
    }
   ],
   "source": [
    "list_files = [file_ for file_ in os.listdir(\"DUMP\") if file_.endswith(\"RESULTS.json\")]\n",
    "json_files = []\n",
    "csvs = []\n",
    "for json_file in list_files:\n",
    "    print(json_file)\n",
    "    with open(\"DUMP/\" + json_file, \"r\") as f:\n",
    "        js = json.load(f)\n",
    "        json_files.append(js)\n",
    "\n",
    "        for d in js:\n",
    "            for key in keys_to_exclude:\n",
    "                d.pop(key, None)\n",
    "        df = pd.DataFrame(js, columns=js[0].keys())\n",
    "        csvs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shots = pd.read_csv(r\"DUMP/Zero_Shots/df_plm_zero_shots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from continual_hate.metrics import transform_df_to_cl_metrics\n",
    "from continual_hate.constants import dict_name_experiments_domain_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
       "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
       "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
       "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
       "       'current_num_samples_training', 'cumulative_samples_trained',\n",
       "       'best_epoch', 'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
       "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
       "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvs[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92009541 0.77163322 0.61613236 0.45396275 0.32757357 0.57422539]\n",
      " [0.92302661 0.77282148 0.61767931 0.46075257 0.37517021 0.61184926]\n",
      " [0.91008693 0.71101846 0.74700826 0.40255542 0.40389242 0.55010259]\n",
      " [0.84682134 0.74879593 0.76944444 0.45574883 0.31652334 0.66657327]\n",
      " [0.76564719 0.62629815 0.80799226 0.49607946 0.5898382  0.46243571]\n",
      " [0.77216698 0.63212937 0.8097566  0.51808434 0.60309565 0.62628985]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88014311 0.57452229 0.51672862 0.17639077 0.60029    0.25525526]\n",
      " [0.88405797 0.57525084 0.50867052 0.18699187 0.61075481 0.3190184 ]\n",
      " [0.8630394  0.45337621 0.68602541 0.07174888 0.61730865 0.1871345 ]\n",
      " [0.78571429 0.54001033 0.74848485 0.60678851 0.5983646  0.45986125]\n",
      " [0.61870504 0.28484848 0.74213836 0.4093473  0.67120181 0.00505051]\n",
      " [0.63033175 0.2962963  0.74476987 0.47275405 0.67697595 0.32098765]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.71005798 0.46869734 0.7204945  0.38561771]\n",
      " [0.47903525 0.83386842 0.40476127 0.39257158]\n",
      " [0.69187675 0.83696986 0.84780488 0.41534452]\n",
      " [0.56410101 0.80772598 0.83627059 0.47210207]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.69353128 0.02684564 0.62655602 0.03969466]\n",
      " [0.24408015 0.71466667 0.04810997 0.04651163]\n",
      " [0.68571429 0.72509004 0.81090909 0.0923994 ]\n",
      " [0.66828087 0.68693009 0.81574803 0.6052211 ]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.46059161 0.71081759 0.60487611]\n",
      " [0.53996159 0.82098362 0.37895637]\n",
      " [0.52222131 0.81896656 0.79750943]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61064718 0.51759364 0.45575221]\n",
      " [0.51172708 0.69004208 0.        ]\n",
      " [0.58947368 0.69575472 0.76013514]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92358201 0.73308903 0.71912625 0.47891657 0.50885045 0.5231014 ]\n",
      " [0.9138639  0.78999148 0.76161249 0.59345695 0.50685008 0.64157697]\n",
      " [0.86900072 0.68201308 0.902687   0.43365201 0.43905881 0.48586543]\n",
      " [0.84790689 0.7415185  0.85605969 0.43337757 0.32484062 0.67570364]\n",
      " [0.78723867 0.59752333 0.75147668 0.42406903 0.66473973 0.46243571]\n",
      " [0.78723867 0.59752333 0.75147668 0.42406903 0.66473973 0.46243571]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88530466 0.49565904 0.62704918 0.21715818 0.63797741 0.14068441]\n",
      " [0.87241379 0.60660248 0.68674699 0.43344334 0.63616792 0.37697842]\n",
      " [0.79764244 0.39621016 0.88057041 0.12573099 0.6208312  0.06584362]\n",
      " [0.78614458 0.52564781 0.83881064 0.61406171 0.59728945 0.4789272 ]\n",
      " [0.6557377  0.22771214 0.64775414 0.10479042 0.65403509 0.00505051]\n",
      " [0.6557377  0.22771214 0.64775414 0.10479042 0.65403509 0.00505051]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.84860622 0.47494725 0.92119672 0.38216031]\n",
      " [0.46939955 0.85015685 0.5489379  0.49146751]\n",
      " [0.77483586 0.75227076 0.93630004 0.44151104]\n",
      " [0.77483586 0.75227076 0.93630004 0.44151104]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.84088514 0.04264392 0.90252708 0.04418262]\n",
      " [0.23381295 0.74529486 0.30538922 0.24415584]\n",
      " [0.76875642 0.56528418 0.92226148 0.1486676 ]\n",
      " [0.76875642 0.56528418 0.92226148 0.1486676 ]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.45657156 0.66895102 0.67290326]\n",
      " [0.64709241 0.85221856 0.40167268]\n",
      " [0.4684845  0.72569464 0.89313761]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61427094 0.4281768  0.52061856]\n",
      " [0.64567984 0.74874372 0.04152249]\n",
      " [0.60393408 0.52774019 0.87017544]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92138169 0.77264977 0.61785761 0.46422801 0.32808658 0.58657674]\n",
      " [0.92654521 0.77897422 0.62132229 0.46832622 0.38456813 0.61666628]\n",
      " [0.91670797 0.75931389 0.7072199  0.45636525 0.39477267 0.61636607]\n",
      " [0.8895435  0.75595263 0.82354325 0.47064568 0.43167938 0.70188628]\n",
      " [0.78506012 0.63433708 0.83195408 0.52818702 0.63808662 0.65676077]\n",
      " [0.80586389 0.65988674 0.82955115 0.52973137 0.62234985 0.79606012]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88214286 0.57697121 0.52205882 0.19544846 0.59922556 0.28075253]\n",
      " [0.8892922  0.58746736 0.51439539 0.20266667 0.61033797 0.33035714]\n",
      " [0.87431694 0.54628225 0.63059701 0.17783858 0.61022044 0.31740614]\n",
      " [0.83648881 0.54375418 0.79194631 0.611901   0.61970393 0.48877147]\n",
      " [0.65625    0.30297398 0.77709611 0.62576009 0.68701376 0.38475499]\n",
      " [0.69247312 0.35425623 0.77484787 0.62165179 0.6841798  0.64850136]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.70484386 0.49400527 0.72062067 0.41724089]\n",
      " [0.70044439 0.83827252 0.73586957 0.42319415]\n",
      " [0.70953577 0.83510693 0.86100339 0.41251189]\n",
      " [0.69354095 0.83321593 0.88016908 0.49113993]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.69805527 0.07472527 0.63326653 0.1038961 ]\n",
      " [0.64981949 0.72162162 0.63181818 0.10650888]\n",
      " [0.68891281 0.717477   0.82462687 0.08682635]\n",
      " [0.71468662 0.72146119 0.85144928 0.61165049]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.48816501 0.68615569 0.63757079]\n",
      " [0.54501676 0.82016141 0.38662337]\n",
      " [0.54450512 0.81743423 0.82244834]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61381896 0.4789357  0.50328228]\n",
      " [0.60541814 0.69200524 0.01403509]\n",
      " [0.58643861 0.68692206 0.78136201]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92138169 0.77264977 0.61785761 0.46422801 0.32808658 0.58657674]\n",
      " [0.92283835 0.77968542 0.61950314 0.46874297 0.39542424 0.61470317]\n",
      " [0.91560444 0.75180779 0.69891668 0.4591756  0.37116834 0.6133069 ]\n",
      " [0.86790959 0.76016456 0.77535217 0.47639172 0.33307381 0.68414945]\n",
      " [0.73107286 0.61431797 0.80402404 0.48988766 0.56619844 0.46504185]\n",
      " [0.73414328 0.62158688 0.80000737 0.52464719 0.5850042  0.66270962]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88214286 0.57697121 0.52205882 0.19544846 0.59922556 0.28075253]\n",
      " [0.88363636 0.5885451  0.51153846 0.20293725 0.61269365 0.32634731]\n",
      " [0.87272727 0.53323594 0.62385321 0.18281037 0.60740741 0.31385643]\n",
      " [0.81072555 0.55767077 0.74440895 0.61611374 0.60038797 0.47905478]\n",
      " [0.55860349 0.26131687 0.73572939 0.45007236 0.66109253 0.01007557]\n",
      " [0.56435644 0.27593152 0.72921109 0.54684512 0.66704481 0.39325843]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.67259893 0.53340529 0.66329626 0.43379972]\n",
      " [0.41100434 0.83135154 0.38280195 0.4100265 ]\n",
      " [0.64788592 0.84054054 0.82669729 0.49589154]\n",
      " [0.62790641 0.81490487 0.83124425 0.46335968]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.6611399  0.16487455 0.56126482 0.13540197]\n",
      " [0.12180747 0.71028037 0.00704225 0.07902736]\n",
      " [0.64154786 0.73333333 0.78635548 0.24736842]\n",
      " [0.67144136 0.69610936 0.8026534  0.60548523]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.48816501 0.68615569 0.63757079]\n",
      " [0.51861159 0.81928244 0.38280195]\n",
      " [0.53361311 0.81373282 0.792214  ]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61381896 0.4789357  0.50328228]\n",
      " [0.48970901 0.6878453  0.00704225]\n",
      " [0.59241706 0.68822171 0.75128645]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92138169 0.77264977 0.61785761 0.46422801 0.32808658 0.58657674]\n",
      " [0.91829173 0.77596572 0.6184169  0.47394649 0.33008194 0.59779167]\n",
      " [0.91829173 0.77596572 0.6184169  0.47394649 0.33008194 0.59779167]\n",
      " [0.91829173 0.77596572 0.6184169  0.47394649 0.33008194 0.59779167]\n",
      " [0.91829173 0.77596572 0.6184169  0.47394649 0.33008194 0.59779167]\n",
      " [0.91829173 0.77596572 0.6184169  0.47394649 0.33008194 0.59779167]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88214286 0.57697121 0.52205882 0.19544846 0.59922556 0.28075253]\n",
      " [0.87787611 0.58359038 0.52380952 0.21671018 0.60087083 0.30268741]\n",
      " [0.87787611 0.58359038 0.52380952 0.21671018 0.60087083 0.30268741]\n",
      " [0.87787611 0.58359038 0.52380952 0.21671018 0.60087083 0.30268741]\n",
      " [0.87787611 0.58359038 0.52380952 0.21671018 0.60087083 0.30268741]\n",
      " [0.87787611 0.58359038 0.52380952 0.21671018 0.60087083 0.30268741]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.71005798 0.46869734 0.7204945  0.38561771]\n",
      " [0.65410119 0.70162379 0.64594388 0.38047208]\n",
      " [0.71301596 0.67352457 0.78874818 0.37705998]\n",
      " [0.70099252 0.77848317 0.85070084 0.59489709]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.69353128 0.02684564 0.62655602 0.03969466]\n",
      " [0.55586592 0.46382189 0.48062016 0.02503912]\n",
      " [0.66824645 0.4120983  0.71367521 0.0188383 ]\n",
      " [0.69949749 0.61403509 0.80916031 0.54490107]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.46938357 0.69050848 0.62448304]\n",
      " [0.5224533  0.79109157 0.38662337]\n",
      " [0.51860472 0.76742185 0.753432  ]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.60814384 0.4784689  0.47086247]\n",
      " [0.59349593 0.64064603 0.01403509]\n",
      " [0.57416268 0.59598854 0.65765766]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92009541 0.77134485 0.6184169  0.46148044 0.32970956 0.57804323]\n",
      " [0.91880588 0.77196407 0.6184169  0.46188973 0.33183054 0.57835726]\n",
      " [0.91880588 0.773028   0.62142311 0.46091764 0.33058492 0.57577735]\n",
      " [0.92012675 0.77504544 0.62416835 0.48273235 0.32035197 0.59386857]\n",
      " [0.91880588 0.77431039 0.62675191 0.47062352 0.33678957 0.57792353]\n",
      " [0.9177102  0.7741015  0.62675191 0.47020407 0.33678957 0.57993528]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88014311 0.57414449 0.52380952 0.19060403 0.60019361 0.26431718]\n",
      " [0.8781362  0.5752381  0.52380952 0.19086022 0.60009695 0.26470588]\n",
      " [0.8781362  0.57692308 0.52495379 0.18867925 0.5998062  0.25892857]\n",
      " [0.88111888 0.58184064 0.53357532 0.23393316 0.59922929 0.29619182]\n",
      " [0.8781362  0.57945118 0.53061224 0.20717131 0.60126275 0.26331361]\n",
      " [0.8765653  0.57908163 0.53061224 0.20689655 0.60126275 0.26666667]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "3  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "4  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "5  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "3          NaN              NaN   NaN                  davidson   \n",
      "4          NaN              NaN   NaN        founta_hateful_57k   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "5          NaN              NaN   NaN             hateval-women   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "3                         NaN                     zero_shot  ...  0.619048   \n",
      "4                         NaN                     zero_shot  ...  0.816092   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "5                         NaN                     zero_shot  ...  0.058824   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "3         0.650794      0.672727    0.6250       0.571429   \n",
      "4         0.966667      0.750000    0.9375       0.666667   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "5         0.500000      0.031250    0.0625       0.000000   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "3              0.444444           0.800000         0.666667   \n",
      "4              1.000000           0.500000         0.965517   \n",
      "1              0.875000           0.875000         0.875000   \n",
      "2              0.800000           0.333333         0.400000   \n",
      "5              0.000000           0.000000         0.117647   \n",
      "6              0.333333           0.250000         0.800000   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "3                0.857143             0.545455  \n",
      "4                0.933333             1.000000  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "5                1.000000             0.062500  \n",
      "6                0.769231             0.833333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.69420463 0.48424431 0.72766403 0.39422396]\n",
      " [0.69815999 0.49086913 0.70926882 0.37700971]\n",
      " [0.69815999 0.49086913 0.70926882 0.37700971]\n",
      " [0.69815999 0.49086913 0.70926882 0.37700971]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.67860906 0.06464646 0.6395112  0.05961252]\n",
      " [0.66888151 0.06726457 0.60515021 0.02457757]\n",
      " [0.66888151 0.06726457 0.60515021 0.02457757]\n",
      " [0.66888151 0.06726457 0.60515021 0.02457757]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "0  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "0          NaN              NaN   NaN                   evalita   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "0                         NaN                     zero_shot  ...  0.304348   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "0         0.218750      0.500000    0.4375       0.608696   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "0              0.437500           1.000000            0.000   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "2              0.800000           0.333333            0.400   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "0                0.000000             0.000000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "2                0.272727             0.750000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.4414824  0.63015214 0.75099085]\n",
      " [0.48975898 0.66938896 0.60036563]\n",
      " [0.4854528  0.66247733 0.69019345]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'diptanu/fBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61436577 0.41674087 0.67073171]\n",
      " [0.61604278 0.44599303 0.4010989 ]\n",
      " [0.61554846 0.44178455 0.56132075]]\n",
      "Getting the zero shot array\n",
      "diptanu/fBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "           model type_experiment  n_trainable_params       cl_technique  \\\n",
      "2  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "6  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "1  diptanu/fBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "   hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "2          NaN              NaN   NaN         hateval-immigrant   \n",
      "6          NaN              NaN   NaN             waseem-racism   \n",
      "1          NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "   dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "2                         NaN                     zero_shot  ...  0.435294   \n",
      "6                         NaN                     zero_shot  ...  0.542857   \n",
      "1                         NaN                     zero_shot  ...  0.875000   \n",
      "\n",
      "   precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "2         0.536364      0.541667    0.4375       0.470588   \n",
      "6         0.551282      0.541667    0.6875       0.285714   \n",
      "1         0.875000      0.875000    0.8750       0.875000   \n",
      "\n",
      "   HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "2              0.800000           0.333333            0.400   \n",
      "6              0.333333           0.250000            0.800   \n",
      "1              0.875000           0.875000            0.875   \n",
      "\n",
      "   NoHATE_precision_score  NoHATE_recall_score  \n",
      "2                0.272727             0.750000  \n",
      "6                0.769231             0.833333  \n",
      "1                0.875000             0.875000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.72478995 0.45964067 0.83844476 0.36736403]\n",
      " [0.44265576 0.84764446 0.38280195 0.39393411]\n",
      " [0.65386154 0.83427924 0.90159716 0.43824646]\n",
      " [0.59283388 0.78496077 0.88660502 0.43664979]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.69506726 0.0047619  0.78615071 0.00314465]\n",
      " [0.17624521 0.73878628 0.00704225 0.04945904]\n",
      " [0.66078431 0.72311213 0.87706422 0.14144272]\n",
      " [0.68566775 0.65302144 0.86754967 0.60727087]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.89997515 0.68993279 0.53143103 0.39733883 0.65070624 0.53903707]\n",
      " [0.89118981 0.70462069 0.4945601  0.39301402 0.63489612 0.56741499]\n",
      " [0.90004365 0.7126849  0.8457338  0.42617988 0.51179328 0.54459624]\n",
      " [0.77188249 0.66933753 0.82105072 0.41101667 0.37591424 0.60842346]\n",
      " [0.81965104 0.64842107 0.79204036 0.36644125 0.59208845 0.46255199]\n",
      " [0.85295207 0.66004988 0.79339784 0.38664545 0.59688106 0.62099874]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.84745763 0.41030195 0.28488372 0.05801527 0.64453665 0.16731518]\n",
      " [0.83396226 0.43859649 0.21538462 0.04923077 0.59818731 0.22053232]\n",
      " [0.85113835 0.45745511 0.81003584 0.1161103  0.63749325 0.18661972]\n",
      " [0.70332481 0.41342075 0.80601504 0.60511791 0.61037037 0.41654357]\n",
      " [0.7114094  0.32770606 0.71269488 0.         0.66358382 0.00506329]\n",
      " [0.76759062 0.35053554 0.71428571 0.0372093  0.66589327 0.31237323]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.74830762 0.45753762 0.84888223 0.36935973]\n",
      " [0.46731506 0.84252596 0.38662337 0.39257158]\n",
      " [0.65278299 0.82587066 0.88829684 0.42205687]\n",
      " [0.5672159  0.75735718 0.8707265  0.4103033 ]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.72766885 0.00456621 0.80392157 0.00628931]\n",
      " [0.22014925 0.73036649 0.01403509 0.04651163]\n",
      " [0.66146341 0.71011236 0.86029412 0.11014493]\n",
      " [0.68450039 0.61743772 0.8525641  0.60660661]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.40034988 0.63878275 0.47663861]\n",
      " [0.63228707 0.84227637 0.38280195]\n",
      " [0.48469394 0.80875346 0.87807589]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'vanilla_ft',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': '',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.59516616 0.35810811 0.17891374]\n",
      " [0.55060034 0.73011734 0.00704225]\n",
      " [0.60260586 0.6873065  0.85053381]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.87483836 0.67760991 0.48320689 0.3927071  0.62904348 0.53047129]\n",
      " [0.87906977 0.70242692 0.48038622 0.39374132 0.63770438 0.56319465]\n",
      " [0.88723844 0.71614792 0.81612569 0.41643185 0.55507751 0.54939993]\n",
      " [0.81187018 0.71005658 0.84421053 0.456709   0.45737873 0.6355992 ]\n",
      " [0.75411857 0.64065672 0.84161355 0.51643468 0.62833501 0.58497208]\n",
      " [0.76932109 0.67353193 0.85052941 0.53981729 0.62549513 0.78621292]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.80632411 0.3862194  0.2006079  0.04915515 0.55621302 0.1532567 ]\n",
      " [0.81395349 0.43424537 0.19195046 0.05198777 0.56362084 0.21292776]\n",
      " [0.8312611  0.4633758  0.77256318 0.09720177 0.65331107 0.19469027]\n",
      " [0.74405594 0.46737968 0.82296651 0.61980503 0.62989691 0.41627247]\n",
      " [0.60368664 0.31439394 0.78838174 0.62095447 0.65131158 0.25373134]\n",
      " [0.63087248 0.37987858 0.804      0.63222222 0.66543892 0.63297872]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.75018836 0.45477527 0.84325914 0.37705478]\n",
      " [0.69678593 0.84329365 0.76508262 0.39196317]\n",
      " [0.71095115 0.82997291 0.87534215 0.39600858]\n",
      " [0.66266863 0.81280934 0.90813034 0.44096205]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.7359491  0.01202405 0.80223881 0.02173913]\n",
      " [0.62886598 0.73221216 0.6741573  0.04636785]\n",
      " [0.70719352 0.7100894  0.84460695 0.05513017]\n",
      " [0.70888303 0.69055375 0.88965517 0.60020768]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.34008764 0.46901259 0.73723712]\n",
      " [0.49060346 0.84030763 0.3904209 ]\n",
      " [0.52689873 0.83966883 0.85207063]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.59894586 0.29421673 0.72058824]\n",
      " [0.61090124 0.72819216 0.02097902]\n",
      " [0.61242938 0.72795031 0.81070746]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.3862634  0.57651125 0.58642289]\n",
      " [0.59212497 0.83172689 0.38280195]\n",
      " [0.47570125 0.80072542 0.90142802]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.60039565 0.2756827  0.37393768]\n",
      " [0.43702906 0.71105193 0.00704225]\n",
      " [0.60651361 0.67545639 0.87943262]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.89307129 0.67900845 0.4733501  0.39135429 0.63579208 0.55966912]\n",
      " [0.89696917 0.71276869 0.48921014 0.39507352 0.64748011 0.59218477]\n",
      " [0.89938982 0.71418211 0.69751416 0.39869776 0.65303044 0.55626933]\n",
      " [0.88502813 0.73711522 0.81554878 0.64247729 0.57998236 0.64517719]\n",
      " [0.87787782 0.66700035 0.72422263 0.37506657 0.64927883 0.46442908]\n",
      " [0.87823044 0.67004145 0.69760584 0.38188104 0.65664461 0.48493412]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.83558994 0.38868613 0.17665615 0.04622496 0.5707196  0.20392157]\n",
      " [0.84250474 0.45430809 0.20496894 0.05487805 0.59407526 0.26716141]\n",
      " [0.84701493 0.45714286 0.56585366 0.06334842 0.66623037 0.19844358]\n",
      " [0.83278689 0.5067043  0.75609756 0.56233878 0.65787966 0.38978495]\n",
      " [0.8097166  0.36398838 0.60532688 0.01569859 0.67715544 0.00995025]\n",
      " [0.81048387 0.36979671 0.56140351 0.02808112 0.67483871 0.04901961]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.7477283  0.46009845 0.86956118 0.36935973]\n",
      " [0.66501533 0.67494166 0.71238223 0.36724356]\n",
      " [0.71542518 0.65459527 0.88050926 0.36990584]\n",
      " [0.69849317 0.73952382 0.91371958 0.66397576]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.72981701 0.0131291  0.83236994 0.00628931]\n",
      " [0.56150507 0.4137931  0.58679707 0.        ]\n",
      " [0.67216981 0.37918216 0.84479371 0.00630915]\n",
      " [0.71085495 0.55380577 0.89292196 0.60098522]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.381274   0.6633697  0.53036672]\n",
      " [0.48692077 0.8083472  0.38280195]\n",
      " [0.51042069 0.7938137  0.68923863]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.59673429 0.41828255 0.27355623]\n",
      " [0.59337017 0.66852368 0.00704225]\n",
      " [0.60056338 0.64183381 0.54498715]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.89696917 0.68480504 0.51984127 0.38982998 0.65214245 0.51367094]\n",
      " [0.89669756 0.6849511  0.51394171 0.38982998 0.65206536 0.51235202]\n",
      " [0.89669756 0.6849511  0.51394171 0.38982998 0.65206536 0.51235202]\n",
      " [0.89669756 0.6849511  0.51394171 0.38982998 0.65206536 0.51235202]\n",
      " [0.89669756 0.6849511  0.51394171 0.38982998 0.65206536 0.51235202]\n",
      " [0.89669756 0.6849511  0.51394171 0.38982998 0.65206536 0.51235202]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.84250474 0.40035746 0.26190476 0.04587156 0.64883402 0.11764706]\n",
      " [0.84190476 0.40036069 0.25149701 0.04587156 0.64591978 0.11451943]\n",
      " [0.84190476 0.40036069 0.25149701 0.04587156 0.64591978 0.11451943]\n",
      " [0.84190476 0.40036069 0.25149701 0.04587156 0.64591978 0.11451943]\n",
      " [0.84190476 0.40036069 0.25149701 0.04587156 0.64591978 0.11451943]\n",
      " [0.84190476 0.40036069 0.25149701 0.04587156 0.64591978 0.11451943]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.34285904 0.64968665 0.80825245]\n",
      " [0.43375704 0.68256907 0.58262342]\n",
      " [0.41444063 0.70558102 0.69980038]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.60019175 0.44741533 0.75146771]\n",
      " [0.60072128 0.43448276 0.36416185]\n",
      " [0.6027259  0.48401826 0.565     ]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "10                   1.0               0.25         0.470588   \n",
      "14                   0.0               0.00         0.608696   \n",
      "9                    0.4               0.25         0.526316   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "10                0.307692             1.000000  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88742831 0.67660147 0.47407389 0.39466927 0.6575648  0.53219055]\n",
      " [0.89971462 0.70949886 0.47089223 0.39765267 0.65355418 0.5565762 ]\n",
      " [0.88618548 0.71016851 0.84769444 0.45569117 0.51888945 0.52889336]\n",
      " [0.73340401 0.67591409 0.82431301 0.38601629 0.41835676 0.56487603]\n",
      " [0.72172801 0.62092832 0.80726524 0.36844618 0.59168677 0.46197047]\n",
      " [0.78587193 0.63721043 0.79946834 0.37677727 0.60698605 0.62465696]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82651072 0.38376384 0.18068536 0.05222734 0.60917722 0.15230461]\n",
      " [0.84688091 0.44794401 0.175      0.05810398 0.61024845 0.2       ]\n",
      " [0.82978723 0.45176849 0.81349911 0.17246175 0.64439655 0.16123499]\n",
      " [0.66425121 0.41991701 0.80495356 0.60433071 0.62027231 0.36935705]\n",
      " [0.54177215 0.27394439 0.73638344 0.00316456 0.66242038 0.005     ]\n",
      " [0.65429234 0.30566802 0.72406181 0.01880878 0.66705952 0.32      ]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "11  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "12  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "13  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "11          NaN              NaN   NaN                  davidson   \n",
      "12          NaN              NaN   NaN        founta_hateful_57k   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "13          NaN              NaN   NaN             hateval-women   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "11                         NaN                     zero_shot  ...  0.360000   \n",
      "12                         NaN                     zero_shot  ...  0.407407   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "13                         NaN                     zero_shot  ...  0.428571   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "11         0.321429      0.409091    0.5625       0.000000   \n",
      "12         0.423077      0.392857    0.6875       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "13         0.500000      0.375000    0.7500       0.000000   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "11                   0.0               0.00         0.720000   \n",
      "12                   0.0               0.00         0.814815   \n",
      "9                    0.4               0.25         0.526316   \n",
      "10                   1.0               0.25         0.470588   \n",
      "13                   0.0               0.00         0.857143   \n",
      "14                   0.0               0.00         0.608696   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "11                0.642857             0.818182  \n",
      "12                0.846154             0.785714  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "13                1.000000             0.750000  \n",
      "14                0.636364             0.583333  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.72478995 0.45964067 0.83844476 0.36736403]\n",
      " [0.70511412 0.4673778  0.76001727 0.36898595]\n",
      " [0.7240243  0.47446055 0.8165665  0.36844618]\n",
      " [0.7240243  0.47446055 0.8165665  0.36844618]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'GroNLP/hateBERT',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.69506726 0.0047619  0.78615071 0.00314465]\n",
      " [0.64112388 0.015      0.66514806 0.0031746 ]\n",
      " [0.67710843 0.02948403 0.75264271 0.00316456]\n",
      " [0.67710843 0.02948403 0.75264271 0.00316456]]\n",
      "Getting the zero shot array\n",
      "GroNLP/hateBERT\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "              model type_experiment  n_trainable_params       cl_technique  \\\n",
      "8   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "14  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "9   GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "10  GroNLP/hateBERT            test           109483778  ZERO_SHOT_TESTING   \n",
      "\n",
      "    hyperparams  experiment_name  time dataset_currently_testing  \\\n",
      "8           NaN              NaN   NaN                   evalita   \n",
      "14          NaN              NaN   NaN             waseem-racism   \n",
      "9           NaN              NaN   NaN                  ibereval   \n",
      "10          NaN              NaN   NaN         hateval-immigrant   \n",
      "\n",
      "    dataset_currently_training dataset_wrt_training_datasets  ...  f1_score  \\\n",
      "8                          NaN                     zero_shot  ...  0.458937   \n",
      "14                         NaN                     zero_shot  ...  0.304348   \n",
      "9                          NaN                     zero_shot  ...  0.417004   \n",
      "10                         NaN                     zero_shot  ...  0.435294   \n",
      "\n",
      "    precision_score  recall_score  accuracy  HATE_f1_score  \\\n",
      "8          0.535714      0.515873    0.5625       0.222222   \n",
      "14         0.318182      0.291667    0.4375       0.000000   \n",
      "9          0.427273      0.437500    0.4375       0.307692   \n",
      "10         0.653846      0.625000    0.4375       0.400000   \n",
      "\n",
      "    HATE_precision_score  HATE_recall_score  NoHATE_f1_score  \\\n",
      "8                    0.5           0.142857         0.695652   \n",
      "14                   0.0           0.000000         0.608696   \n",
      "9                    0.4           0.250000         0.526316   \n",
      "10                   1.0           0.250000         0.470588   \n",
      "\n",
      "    NoHATE_precision_score  NoHATE_recall_score  \n",
      "8                 0.571429             0.888889  \n",
      "14                0.636364             0.583333  \n",
      "9                 0.454545             0.625000  \n",
      "10                0.307692             1.000000  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92210771 0.74343453 0.65632166 0.47661395 0.52442786 0.52963925]\n",
      " [0.92632164 0.7745331  0.69087993 0.58762815 0.4456755  0.59670436]\n",
      " [0.92632164 0.7745331  0.69087993 0.58762815 0.4456755  0.59670436]\n",
      " [0.92632164 0.7745331  0.69087993 0.58762815 0.4456755  0.59670436]\n",
      " [0.92632164 0.7745331  0.69087993 0.58762815 0.4456755  0.59670436]\n",
      " [0.92632164 0.7745331  0.69087993 0.58762815 0.4456755  0.59670436]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88288288 0.51607963 0.53418803 0.21265141 0.64235166 0.15087041]\n",
      " [0.89152542 0.57849031 0.6023166  0.42669584 0.62455059 0.290625  ]\n",
      " [0.89152542 0.57849031 0.6023166  0.42669584 0.62455059 0.290625  ]\n",
      " [0.89152542 0.57849031 0.6023166  0.42669584 0.62455059 0.290625  ]\n",
      " [0.89152542 0.57849031 0.6023166  0.42669584 0.62455059 0.290625  ]\n",
      " [0.89152542 0.57849031 0.6023166  0.42669584 0.62455059 0.290625  ]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.84130874 0.4716878  0.91535944 0.38064075]\n",
      " [0.81352292 0.84720427 0.90162521 0.49706644]\n",
      " [0.79499815 0.84514735 0.90215771 0.53496086]\n",
      " [0.79499815 0.84514735 0.90215771 0.53496086]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.83083512 0.03789474 0.89530686 0.04637681]\n",
      " [0.79692645 0.74027604 0.87452471 0.25482625]\n",
      " [0.79561316 0.74039581 0.87884268 0.33796296]\n",
      " [0.79561316 0.74039581 0.87884268 0.33796296]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.44247458 0.64854167 0.59281899]\n",
      " [0.47446334 0.84558025 0.41207997]\n",
      " [0.51990562 0.83982283 0.88013331]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'agem',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mem_size_proportion=0.025',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.6146789  0.37942122 0.38418079]\n",
      " [0.61049285 0.7382716  0.06143345]\n",
      " [0.60509915 0.72772898 0.84859813]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.9217285  0.73948689 0.72243176 0.49016739 0.54105049 0.52891525]\n",
      " [0.91922938 0.78637383 0.721276   0.58505489 0.53132937 0.64742206]\n",
      " [0.90258651 0.7107586  0.87565324 0.50380319 0.48782595 0.52285351]\n",
      " [0.8400501  0.73479006 0.8545135  0.45034898 0.36773035 0.68102593]\n",
      " [0.50619287 0.49237291 0.57161372 0.40710644 0.44158533 0.46025615]\n",
      " [0.50619287 0.49237291 0.57161372 0.40710644 0.44158533 0.46025615]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88203267 0.50786164 0.62761506 0.24052288 0.64487535 0.15151515]\n",
      " [0.88       0.59958362 0.62068966 0.41619798 0.63671658 0.38461538]\n",
      " [0.85239852 0.45270816 0.84859155 0.25984252 0.62978723 0.14041746]\n",
      " [0.77695716 0.51443299 0.83647799 0.61938776 0.60826772 0.49312557]\n",
      " [0.14886731 0.02160864 0.34502924 0.07328244 0.14492754 0.        ]\n",
      " [0.14886731 0.02160864 0.34502924 0.07328244 0.14492754 0.        ]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82635386 0.4741533  0.91066814 0.38561495]\n",
      " [0.45264904 0.85636067 0.59765123 0.45662779]\n",
      " [0.76175604 0.70617367 0.93305429 0.40691197]\n",
      " [0.58984534 0.76255414 0.91373759 0.43649953]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.81576145 0.03921569 0.88888889 0.04747774]\n",
      " [0.19813084 0.75621891 0.39093484 0.17134831]\n",
      " [0.75413223 0.48051948 0.91756272 0.08247423]\n",
      " [0.69730586 0.6237534  0.8998358  0.61280488]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.44840086 0.69748107 0.66951399]\n",
      " [0.64308523 0.86020184 0.39419479]\n",
      " [0.48664384 0.75869725 0.89576371]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'ewc',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'ewc_lambda=1500',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.61435897 0.47711512 0.51428571]\n",
      " [0.64499005 0.76226415 0.02787456]\n",
      " [0.6        0.58119658 0.87279152]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92614644 0.74577024 0.69938017 0.49232923 0.52324075 0.55883083]\n",
      " [0.92996914 0.76851728 0.70867216 0.50310858 0.52442786 0.5926471 ]\n",
      " [0.92714239 0.72896659 0.83929912 0.4479514  0.46345156 0.5137959 ]\n",
      " [0.92047343 0.75314666 0.85873645 0.70021009 0.42236052 0.58987295]\n",
      " [0.8704041  0.66212704 0.84088264 0.40645706 0.54761095 0.47109876]\n",
      " [0.87342919 0.66638483 0.82283773 0.44650925 0.57986406 0.52523783]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.88928571 0.52081756 0.59917355 0.24611399 0.64502165 0.21071429]\n",
      " [0.89520426 0.56421678 0.60554371 0.26444159 0.64235166 0.2755102 ]\n",
      " [0.88888889 0.48621554 0.79303675 0.15406562 0.62857143 0.11952191]\n",
      " [0.88099467 0.53493614 0.82585278 0.63481229 0.61974684 0.27181208]\n",
      " [0.7966805  0.35465116 0.78850103 0.07305936 0.64349776 0.02427184]\n",
      " [0.80165289 0.36275461 0.76109937 0.14964029 0.64836449 0.12844037]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82591353 0.47282468 0.91219512 0.38200729]\n",
      " [0.76084184 0.5214849  0.86768116 0.38071932]\n",
      " [0.80314782 0.50404755 0.90873849 0.38561771]\n",
      " [0.80314782 0.50404755 0.90873849 0.38561771]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.81216069 0.03539823 0.89090909 0.03363914]\n",
      " [0.70918367 0.12064965 0.82703777 0.02790698]\n",
      " [0.78405316 0.09271523 0.88560886 0.03969466]\n",
      " [0.78405316 0.09271523 0.88560886 0.03969466]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.40021924 0.71218254 0.65187258]\n",
      " [0.43861718 0.81738491 0.47746289]\n",
      " [0.43861718 0.81738491 0.47746289]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'lwf',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'lwf_lambda=1_temperature=2',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.60428074 0.50209205 0.48404255]\n",
      " [0.60789339 0.68814433 0.17948718]\n",
      " [0.60789339 0.68814433 0.17948718]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.92783745 0.7379925  0.70847237 0.50245252 0.51397299 0.54028651]\n",
      " [0.92339842 0.73963387 0.70811404 0.51212987 0.49907262 0.54685338]\n",
      " [0.9344102  0.73094286 0.72230357 0.49234336 0.52666212 0.52834673]\n",
      " [0.89346133 0.74585436 0.76280702 0.66500875 0.4307272  0.61128716]\n",
      " [0.92413685 0.73483588 0.74448563 0.58175695 0.54248247 0.55146024]\n",
      " [0.92302661 0.73623735 0.74448563 0.58234207 0.54075205 0.55773751]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4293),\n",
      " 'experiment_name': 'davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(5)}\n",
      "Experiment ->  davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "Datasets trained ->\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.89130435 0.50638618 0.6317757  0.25882353 0.63779101 0.17407407]\n",
      " [0.88489209 0.50997783 0.63333333 0.27877238 0.63383298 0.18928571]\n",
      " [0.90073529 0.49228395 0.64503817 0.2393617  0.64113786 0.14942529]\n",
      " [0.84552846 0.52906287 0.73046252 0.60131796 0.61829331 0.33062331]\n",
      " [0.88566243 0.5        0.67304015 0.40820981 0.64598338 0.19600726]\n",
      " [0.88405797 0.50266565 0.67304015 0.41043084 0.6452684  0.20825853]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "davidson-TO-founta_hateful_57k-TO-ibereval-TO-hateval-immigrant-TO-hateval-women-TO-waseem-racism\n",
      "['davidson', 'founta_hateful_57k', 'ibereval', 'hateval-immigrant', 'hateval-women', 'waseem-racism']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "19  FacebookAI/roberta-base            test           124647170   \n",
      "20  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "21  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "19  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "20  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "21  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "19                  davidson                         NaN   \n",
      "20        founta_hateful_57k                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "21             hateval-women                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "19                     zero_shot  ...  0.238095          0.15625   \n",
      "20                     zero_shot  ...  0.111111          0.06250   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "21                     zero_shot  ...  0.000000          0.00000   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "19           0.5    0.3125       0.476190                0.3125   \n",
      "20           0.5    0.1250       0.222222                0.1250   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "21           0.0    0.0000       0.000000                0.0000   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "19                1.0              0.0                     0.0   \n",
      "20                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "21                0.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "19                  0.0  \n",
      "20                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "21                  0.0  \n",
      "22                  0.0  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.82635386 0.4741533  0.91066814 0.38561495]\n",
      " [0.82210322 0.48266846 0.90887374 0.389129  ]\n",
      " [0.82210322 0.48266846 0.90887374 0.389129  ]\n",
      " [0.82210322 0.48266846 0.90887374 0.389129  ]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4799),\n",
      " 'experiment_name': 'evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(3)}\n",
      "Experiment ->  evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "Datasets trained ->\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.81576145 0.03921569 0.88888889 0.04747774]\n",
      " [0.80947255 0.05321508 0.88602941 0.05333333]\n",
      " [0.80947255 0.05321508 0.88602941 0.05333333]\n",
      " [0.80947255 0.05321508 0.88602941 0.05333333]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "evalita-TO-waseem-racism-TO-ibereval-TO-hateval-immigrant\n",
      "['evalita', 'waseem-racism', 'ibereval', 'hateval-immigrant']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "16  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "16  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "16                   evalita                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "18         hateval-immigrant                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "16                     zero_shot  ...  0.304348          0.21875   \n",
      "22                     zero_shot  ...  0.200000          0.12500   \n",
      "17                     zero_shot  ...  0.333333          0.25000   \n",
      "18                     zero_shot  ...  0.428571          0.37500   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "16           0.5    0.4375       0.608696                0.4375   \n",
      "22           0.5    0.2500       0.400000                0.2500   \n",
      "17           0.5    0.5000       0.666667                0.5000   \n",
      "18           0.5    0.7500       0.857143                0.7500   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "16                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "18                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "16                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "18                  0.0  \n",
      "\n",
      "[4 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "\n",
      "Matrix Computed\n",
      "[[0.40278884 0.63227764 0.77950122]\n",
      " [0.4576285  0.65142454 0.70343137]\n",
      " [0.39449979 0.71400248 0.78697318]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "Metadata for current DF\n",
      "dict_keys(['model', 'cl_technique', 'experiment_name', 'time', 'best_epochs', 'current_num_samples_training', 'learning_rate', 'hyperparams'])\n",
      "{'best_epochs': np.int64(8),\n",
      " 'cl_technique': 'mas',\n",
      " 'current_num_samples_training': np.int64(4500),\n",
      " 'experiment_name': 'hateval-immigrant-TO-waseem-racism-TO-ibereval',\n",
      " 'hyperparams': 'mas_lambda=1000_mas_variation=global',\n",
      " 'learning_rate': np.float64(1e-05),\n",
      " 'model': 'FacebookAI/roberta-base',\n",
      " 'time': np.int64(2)}\n",
      "Experiment ->  hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "Datasets trained ->\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix Computed\n",
      "[[0.60557769 0.36538462 0.70539419]\n",
      " [0.6074229  0.37847222 0.57352941]\n",
      " [0.6049505  0.51644336 0.71919192]]\n",
      "Getting the zero shot array\n",
      "FacebookAI/roberta-base\n",
      "hateval-immigrant-TO-waseem-racism-TO-ibereval\n",
      "['hateval-immigrant', 'waseem-racism', 'ibereval']\n",
      "Index(['model', 'type_experiment', 'n_trainable_params', 'cl_technique',\n",
      "       'hyperparams', 'experiment_name', 'time', 'dataset_currently_testing',\n",
      "       'dataset_currently_training', 'dataset_wrt_training_datasets',\n",
      "       'target_epochs', 'best_epochs', 'learning_rate', 'batch_size',\n",
      "       'current_num_samples_training', 'cumulative_samples_trained',\n",
      "       'f1_score', 'precision_score', 'recall_score', 'accuracy',\n",
      "       'HATE_f1_score', 'HATE_precision_score', 'HATE_recall_score',\n",
      "       'NoHATE_f1_score', 'NoHATE_precision_score', 'NoHATE_recall_score'],\n",
      "      dtype='object')\n",
      "ZERO SHOT ARRAY\n",
      "                      model type_experiment  n_trainable_params  \\\n",
      "18  FacebookAI/roberta-base            test           124647170   \n",
      "22  FacebookAI/roberta-base            test           124647170   \n",
      "17  FacebookAI/roberta-base            test           124647170   \n",
      "\n",
      "         cl_technique  hyperparams  experiment_name  time  \\\n",
      "18  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "22  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "17  ZERO_SHOT_TESTING          NaN              NaN   NaN   \n",
      "\n",
      "   dataset_currently_testing  dataset_currently_training  \\\n",
      "18         hateval-immigrant                         NaN   \n",
      "22             waseem-racism                         NaN   \n",
      "17                  ibereval                         NaN   \n",
      "\n",
      "   dataset_wrt_training_datasets  ...  f1_score  precision_score  \\\n",
      "18                     zero_shot  ...  0.428571            0.375   \n",
      "22                     zero_shot  ...  0.200000            0.125   \n",
      "17                     zero_shot  ...  0.333333            0.250   \n",
      "\n",
      "    recall_score  accuracy  HATE_f1_score  HATE_precision_score  \\\n",
      "18           0.5      0.75       0.857143                  0.75   \n",
      "22           0.5      0.25       0.400000                  0.25   \n",
      "17           0.5      0.50       0.666667                  0.50   \n",
      "\n",
      "    HATE_recall_score  NoHATE_f1_score  NoHATE_precision_score  \\\n",
      "18                1.0              0.0                     0.0   \n",
      "22                1.0              0.0                     0.0   \n",
      "17                1.0              0.0                     0.0   \n",
      "\n",
      "    NoHATE_recall_score  \n",
      "18                  0.0  \n",
      "22                  0.0  \n",
      "17                  0.0  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].astype(\"category\")\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots[dataset_test_results_column] = filtered_zero_shots[dataset_test_results_column].cat.set_categories(in_training)\n",
      "C:\\Users\\alber\\Desktop\\Continual Learning M-THESIS\\1.5 Notebooks NSCC\\continual_hate\\metrics.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_zero_shots.sort_values([dataset_test_results_column], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dfs_cl = []\n",
    "for df in csvs:\n",
    "    df_cl_metrics = transform_df_to_cl_metrics(df, \n",
    "                                zero_shots, \n",
    "                                performance_column=\"f1_score\", \n",
    "                                experiment_name_column=\"experiment_name\", \n",
    "                                dataset_test_results_column=\"dataset_currently_testing\", \n",
    "                                dataset_current_training_column=\"dataset_currently_training\", \n",
    "                                time_column=\"time\",\n",
    "                                model_name_column=\"model\", \n",
    "                                dataset_dict_trainings=dict_name_experiments_domain_transfer)\n",
    "    dfs_cl.append(df_cl_metrics)\n",
    "\n",
    "    df_cl_metrics = transform_df_to_cl_metrics(df, \n",
    "                                zero_shots, \n",
    "                                performance_column=\"HATE_f1_score\", \n",
    "                                experiment_name_column=\"experiment_name\", \n",
    "                                dataset_test_results_column=\"dataset_currently_testing\", \n",
    "                                dataset_current_training_column=\"dataset_currently_training\", \n",
    "                                time_column=\"time\",\n",
    "                                model_name_column=\"model\", \n",
    "                                dataset_dict_trainings=dict_name_experiments_domain_transfer)\n",
    "    dfs_cl.append(df_cl_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_cl = pd.concat(dfs_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cl_technique</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>time</th>\n",
       "      <th>best_epochs</th>\n",
       "      <th>current_num_samples_training</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>last</th>\n",
       "      <th>avg_incremental_f1</th>\n",
       "      <th>transfer</th>\n",
       "      <th>bwt</th>\n",
       "      <th>fw_transfer</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.614581</td>\n",
       "      <td>0.762119</td>\n",
       "      <td>0.757924</td>\n",
       "      <td>-0.097866</td>\n",
       "      <td>0.328523</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>vanilla_ft</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td></td>\n",
       "      <td>0.382513</td>\n",
       "      <td>0.641329</td>\n",
       "      <td>0.610642</td>\n",
       "      <td>-0.270109</td>\n",
       "      <td>-0.047111</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.670290</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.398261</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>agem</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mem_size_proportion=0.025</td>\n",
       "      <td>0.569034</td>\n",
       "      <td>0.687862</td>\n",
       "      <td>0.713357</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.062847</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FacebookAI/roberta-base</td>\n",
       "      <td>ewc</td>\n",
       "      <td>davidson-TO-founta_hateful_57k-TO-ibereval-TO-...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>4293</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>ewc_lambda=1500</td>\n",
       "      <td>0.479855</td>\n",
       "      <td>0.714625</td>\n",
       "      <td>0.702756</td>\n",
       "      <td>-0.211364</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>ewc</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>ewc_lambda=1500</td>\n",
       "      <td>0.677308</td>\n",
       "      <td>0.626635</td>\n",
       "      <td>0.565014</td>\n",
       "      <td>-0.010513</td>\n",
       "      <td>-0.337368</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>lwf</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>lwf_lambda=1_temperature=2</td>\n",
       "      <td>0.679820</td>\n",
       "      <td>0.601992</td>\n",
       "      <td>0.582733</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>-0.170363</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>lwf</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>lwf_lambda=1_temperature=2</td>\n",
       "      <td>0.609270</td>\n",
       "      <td>0.611495</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>-0.039319</td>\n",
       "      <td>-0.334105</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>mas</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mas_lambda=1000_mas_variation=global</td>\n",
       "      <td>0.612708</td>\n",
       "      <td>0.544588</td>\n",
       "      <td>0.531862</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>-0.093670</td>\n",
       "      <td>f1_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diptanu/fBERT</td>\n",
       "      <td>mas</td>\n",
       "      <td>hateval-immigrant-TO-waseem-racism-TO-ibereval</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>mas_lambda=1000_mas_variation=global</td>\n",
       "      <td>0.539551</td>\n",
       "      <td>0.561645</td>\n",
       "      <td>0.572355</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>-0.171437</td>\n",
       "      <td>HATE_f1_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model cl_technique  \\\n",
       "0   FacebookAI/roberta-base   vanilla_ft   \n",
       "0   FacebookAI/roberta-base   vanilla_ft   \n",
       "0   FacebookAI/roberta-base         agem   \n",
       "0   FacebookAI/roberta-base         agem   \n",
       "0   FacebookAI/roberta-base          ewc   \n",
       "..                      ...          ...   \n",
       "0             diptanu/fBERT          ewc   \n",
       "0             diptanu/fBERT          lwf   \n",
       "0             diptanu/fBERT          lwf   \n",
       "0             diptanu/fBERT          mas   \n",
       "0             diptanu/fBERT          mas   \n",
       "\n",
       "                                      experiment_name  time  best_epochs  \\\n",
       "0   davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0   davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0   davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0   davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "0   davidson-TO-founta_hateful_57k-TO-ibereval-TO-...     5            8   \n",
       "..                                                ...   ...          ...   \n",
       "0      hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0      hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0      hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0      hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "0      hateval-immigrant-TO-waseem-racism-TO-ibereval     2            8   \n",
       "\n",
       "    current_num_samples_training  learning_rate  \\\n",
       "0                           4293        0.00001   \n",
       "0                           4293        0.00001   \n",
       "0                           4293        0.00001   \n",
       "0                           4293        0.00001   \n",
       "0                           4293        0.00001   \n",
       "..                           ...            ...   \n",
       "0                           4500        0.00001   \n",
       "0                           4500        0.00001   \n",
       "0                           4500        0.00001   \n",
       "0                           4500        0.00001   \n",
       "0                           4500        0.00001   \n",
       "\n",
       "                             hyperparams      last  avg_incremental_f1  \\\n",
       "0                                         0.614581            0.762119   \n",
       "0                                         0.382513            0.641329   \n",
       "0              mem_size_proportion=0.025  0.670290            0.778320   \n",
       "0              mem_size_proportion=0.025  0.569034            0.687862   \n",
       "0                        ewc_lambda=1500  0.479855            0.714625   \n",
       "..                                   ...       ...                 ...   \n",
       "0                        ewc_lambda=1500  0.677308            0.626635   \n",
       "0             lwf_lambda=1_temperature=2  0.679820            0.601992   \n",
       "0             lwf_lambda=1_temperature=2  0.609270            0.611495   \n",
       "0   mas_lambda=1000_mas_variation=global  0.612708            0.544588   \n",
       "0   mas_lambda=1000_mas_variation=global  0.539551            0.561645   \n",
       "\n",
       "    transfer       bwt  fw_transfer         metric  \n",
       "0   0.757924 -0.097866     0.328523       f1_score  \n",
       "0   0.610642 -0.270109    -0.047111  HATE_f1_score  \n",
       "0   0.800768  0.000843     0.398261       f1_score  \n",
       "0   0.713357  0.001729     0.062847  HATE_f1_score  \n",
       "0   0.702756 -0.211364     0.343907       f1_score  \n",
       "..       ...       ...          ...            ...  \n",
       "0   0.565014 -0.010513    -0.337368  HATE_f1_score  \n",
       "0   0.582733  0.012776    -0.170363       f1_score  \n",
       "0   0.589286 -0.039319    -0.334105  HATE_f1_score  \n",
       "0   0.531862  0.018529    -0.093670       f1_score  \n",
       "0   0.572355 -0.001513    -0.171437  HATE_f1_score  \n",
       "\n",
       "[90 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_cl.sort_values([\"model\", \"experiment_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_cl.to_csv(\"df_cl_metrics_ES.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
